\section{Implementierung der Simulation}
\label{sec:implSimulation}

Für die Ausführung der Simulation wurden zwei grundlegende Tests implementiert.
Das ist zum einen eine reine Simulation ohne die Aktivierung von Komponentenfehlern, sowie ein weiterer Test, bei dem Komponentenfehler aktiviert werden können.
Ausgeführt werden können die Tests mithilfe des NUnit"=Frameworks.

\subsection{Grundlegender Aufbau}
\label{sec:simulationBasics}

Da im realen Cluster Hadoop kontinuierlich Anpassungen durchführt und Tests in \ac{ss} mit diskreten Schritten durchgeführt werden, muss beachtet werden, dass die Werte, die beim Test ermittelt werden, immer nur Momentaufnahmen darstellen.
Ebenso muss beachtet werden, dass bei der Deaktivierung von einzelnen Nodes bzw. deren Netzwerkverbindungen diese nicht in Echtzeit, sondern um einige Zeit verzögert erkannt werden und erst nach einer gewissen Zeit aus der Konfiguration des Clusters entfernt werden.
Genauso verhält es sich, wenn ein Node bzw. seine Verbindung wieder aktiviert wird, da dieser zunächst gestartet und die Verbindung mit den YARN"=Controller wiederhergestellt werden muss.
Außerdem werden die für die auf dem Cluster ausgeführten Anwendungen benötigten \ac{AppMstr} und YARN"=Container aufgrund der komplexen internen Prozesse von Hadoop nicht innerhalb weniger Millisekunden allokiert, sondern benötigen ebenfalls eine gewisse Zeit.
Aus diesen Gründen muss ein Simulations"=Schritt um eine gewisse Zeit verzögert werden, sodass alle Aktivitäten innerhalb von Hadoop genügend Zeit zur Ausführung erhalten.

Der grundlegende Ablauf einer Simulation sieht wie folgt aus:

\lstinputlisting[label=lst:hadoopSimulation,style=cs,
caption={[Simulation in dieser Fallstudie]
    Simulation in dieser Fallstudie (gekürzt).}]
{./listings/hadoopSimulation.cs}

Da der Ablauf der Simulation unabhängig von der Aktivierung der Komponentenfehler der gleiche ist, ist hier nur die Variante ohne deren Aktivierung aufgezeigt.
Im Falle einer Aktivierung der Komponentenfehler unterscheiden sich beide Simulationsvarianten nur durch die Angabe der generellen Wahrscheinlichkeiten zum Aktivieren und Deaktivieren der Komponentenfehler.
Da die einzelnen Schritte einer Simulation eine gewisse Mindestdauer haben, wird nach jedem Schritt geprüft, wie viel Zeit für die Ausführung des Schrittes benötigt wurde.
Liegt die Zeit unterhalb der Mindestdauer für einen Schritt, wird die Ausführung des nächsten Schrittes solange hinausgezögert, bis die Mindestdauer des Schrittes erreicht wurde.
Weitere zeitliche Verzögerungen während der Ausführung eines Simulations"=Schrittes sind in \autoref{sec:simulationStep} beschrieben.

Wenn während der Simulation eine im Modell nicht behandelte \texttt{Exception} auftritt, wird diese außerhalb der Simulation abgefangen und entsprechend geloggt.
Dadurch wird zudem die Simulation beim aktuellen Stand abgebrochen.
Nach Abschluss der Simulation werden immer alle zu dem Zeitpunkt mit Komponentenfehlern injizierten Nodes neu gestartet.

\subsection{Initialisierung des Modells}
\label{sec:simulationModelInit}

Bevor das Modell im Simulator ausgeführt werden kann, muss es initialisiert werden.
Das folgende \autoref{lst:hadoopSimulationInit} zeigt die Definition der Felder zur Modellinitialisierung sowie die entsprechenden Methoden, die in \autoref{lst:hadoopSimulation} zur Initialisierung aufgerufen werden:

\lstinputlisting[label=lst:hadoopSimulationInit,style=cs,
caption={Initialisierung des Modells für die Simulation}]
{./listings/hadoopSimulationInit.cs}

Die einzelnen Eigenschaften für die Simulation werden vor dem Initialisieren des Modells in den \texttt{ModelSettings} gespeichert.
Die dort gespeicherten Werte werden wiederum zum Initialisieren der Modell"=Instanz bzw. während der Ausführung der Simulation genutzt.

Einige Eigenschaften haben lediglich einen Zweck, während andere umfangreichere Auswirkungen besitzen.
Die einfachen Eigenschaften sind:

\begin{description}
    \item [MinStepTime] \hfill \\
        Definiert die Mindestdauer eines Schrittes.
        
    \item[BenchmarkSeed] \hfill \\
        Gibt den Seed an, mit dem die Zufallsgeneratoren in den Klassen \texttt{Benchmark""Controller} und \texttt{NodeFaultAttribute} initialisiert werden.
        Dadurch wird es ermöglicht, einzelne Testfälle erneut ausführen zu können.
        
    \item[StepCount] \hfill \\
        Definiert die Anzahl der ausgeführten Schritte.
        
    \item[FaultActivationProbability] \hfill \\
        Definiert die generelle Häufigkeit zum Aktivieren von Komponentenfehlern.
        Ist dieser Wert 0,0, werden grundsätzlich keine Komponentenfehler aktiviert, bei einem Wert von 1,0 werden Komponentenfehler dagegen immer aktiviert.
        
    \item[FaultRepariProbability] \hfill \\
        Definiert die generelle Häufigkeit zum Deaktivieren von Komponentenfehlern.
        Die hier definierte Wahrscheinlichkeit verhält sich analog zu \texttt{\_FaultActivation""Probability}.
        Bei einem Wert von 0,0 werden Komponentenfehler niemals deaktiviert, während sie bei einem Wert von 1,0 im nachfolgenden Schritt immer deaktiviert werden.
        
    \item[HostsCount] \hfill \\
        Definiert die Anzahl der in der Simulation verwendeten Hosts.
        Benötigt wird dieser Wert, damit zu jedem verwendeten Host eine SSH"=Verbindung aufgebaut werden kann.
        
    \item[NodeBaseCount] \hfill \\
        Definiert die Anzahl der Nodes auf Host1.
        Auf Host2 wird die Hälfte der Nodes verwendet.
        Benötigt wird dieser Wert, um mithilfe der REST"=API auf die Hadoop"=Nodes zugreifen zu können, um die Daten der YARN"=Container zu ermitteln.
        
    \item[ClientCount] \hfill \\
        Definiert die Anzahl der zu simulierenden Clients.
        Da jeder Client gleichzeitig nur eine Anwendung startet, wird dadurch gleichzeitig definiert, wie viele Anwendungen gleichzeitig auf dem Cluster ausgeführt werden sollen.
\end{description}

Eine Besonderheit bildet die Eigenschaft \texttt{PrecreatedInputs}.
Es definiert, ob die ausgeführten Anwendungen auf dem Cluster vorab generierte Eingabedaten nutzen oder alle Eingabedaten während der Ausführung selbst generieren.
Der Unterschied zwischen beiden Varianten liegt darin, dass vorab generierte Eingabedaten in einem anderen Verzeichnis im \ac{HDFS} gespeichert sind und während der Simulation die Eingabedaten aus diesem Verzeichnis gelesen werden.
Wenn keine Eingabedaten vorab generiert werden, werden als Eingabeverzeichnisse für die Anwendungen die Ausgabeverzeichnisse der entsprechenden Benchmarks genutzt, die die dafür benötigten Daten generieren.
Die Eigenschaft \texttt{RecreatePreInputs} definiert hierfür, ob bereits bestehende Eingabedaten neu generiert werden, was standardmäßig nicht der Fall ist bzw. dieses Feld auf \texttt{false} gesetzt ist.
Der genaue Ablauf der Bereitstellung der Eingabedaten wird in \todo{Vorabgenerierung der Eingabedaten irgendwo schreiben und hier drauf verweisen} beschrieben.

Die Auswirkungen der in \texttt{InitModel()} definierten Einstellung \texttt{ModelSettings.Host""Mode} wird bereits in \todo{ModelSettings.HostMode beschrieben und hier verweisen} beschrieben.

Die direkt im Anschluss an die Initialisierung des Simulators ausgerufene Methode \texttt{CollectYarnNodeFaults()} ermittelt alle im initialisierten Modell enthaltenen Komponentenfehler, die mit dem \texttt{NodeFaultAttribute} markiert sind:

\lstinputlisting[label=lst:hadoopSimulationCollectFaults,style=cs,
caption={[Ermitteln der Komponentenfehler mit dem NodeFaultAttribute]
    Ermitteln der Komponentenfehler mit dem \texttt{NodeFaultAttribute}}]
{./listings/hadoopSimulationCollectFaults.cs}

Die gefundenen Komponentenfehler werden als Array aus Tupel, bestehend aus dem Komponentenfehler selbst, dem Attribut sowie dem dazugehörigen Node zurückgegeben.
Zur Speicherung hierfür dient der Typ \texttt{FaultTuple}, welcher ein Alias für das hierfür genutzte \texttt{Tupel<T>} darstellt.
Die jeweiligen Instanzen der Attribute und Nodes werden für die in \autoref{sec:simulationFaultActivation} beschriebene Aktivierung der dazugehörigen Komponentenfehler benötigt.
Die beiden im Tupel gespeicherten Instanzen des \texttt{IntWrapper} dienen zur Speicherung der Anzahl der Aktivierungen bzw. Deaktivierungen der Komponentenfehler.
Da der Wert einer Struktur wie \texttt{int} nicht direkt in einem Tupel geändert werden kann, dient die Klasse \texttt{IntWrapper} hierfür als Adapter.

\subsection{Ablauf eines Simulations"=Schrittes}
\label{sec:simulationStep}

Der Ablauf eines Schrittes lässt sich in die folgenden fünf Abschnitte einteilen.
Während die \nameref{sec:simulationFaultActivation} komplett außerhalb des ausgeführten Modells erfolgt (durch die in \autoref{lst:hadoopSimulation} aufgerufene \texttt{HandleFaults()}"=Methode), werden die anderen Abschnitte durch die \texttt{Update()}"=Methode des \texttt{YarnController}s innerhalb des Modells während der Ausführung eines Simulations"=Schrittes ausgeführt.
Die \nameref{sec:simulationStepOutput} werden dagegen gemischt durchgeführt.

\subsubsection{Aktivierung und Deaktivierung der Komponentenfehler}
\label{sec:simulationFaultActivation}

Zur Aktivierung der Komponentenfehler gibt es drei Einzelschritte.
Der erste Schritt ist die Prüfung, ob der Fehler bereits aktiviert wurde.
Bei einem derzeit nicht injizierten Komponentenfehler, wird im zweiten Schritt geprüft, ob der Fehler aktiviert werden soll bevor er im dritten Schritt im realen Cluster injiziert wird.

Zur Entscheidung, ob ein Komponentenfehler aktiviert wird, hängt von folgenden Parametern ab:

\begin{itemize}
    \item Von der Auslastung des Nodes im vorhergehenden Simulationsschritt,
    \item von der in \texttt{ModelSettings.FaultActivationProbability} definierten generellen Wahrscheinlichkeit zur Fehleraktivierung,
    \item sowie von einer Zufallszahl.
\end{itemize}

Ob ein Komponentenfehler aktiviert wird, wird folgendermaßen anhand dieser Parameter berechnet:

\lstinputlisting[label=lst:faultActivationCalc,style=cs,
caption={[Berechnung der Aktivierung von Komponentenfehlern]
    Berechnung der Aktivierung von Komponentenfehlern (zusammengefasst).}]
{./listings/faultActivationCalc.cs}

Die Entscheidung zur Deaktivierung eines Komponentenfehlers verhält sich analog.
Anstatt der generellen Aktivierungswahrscheinlichkeit in \texttt{ModelSettings.Fault""ActivationProbability} wird hierbei die generelle Wahrscheinlichkeit zur Deaktivierung in \texttt{ModelSettings.FaultRepairProbability} genutzt.
Außerdem spielt bei der Deaktivierung die Auslastung des Nodes zum Zeitpunkt der Aktivierung eine Rolle, welche hierzu in Zeile 7 in \autoref{lst:faultActivationCalc} entsprechend gespeichert wird.
Der grundlegende Algorithmus zur Entscheidung ist jedoch gleich.

\subsubsection{Ausführung Benchmarks}
\label{sec:simulationBenchmarkExecution}

Damit die Ausführung der Benchmarks vor dem Monitoring der Anwendungen sowie dem Auswerten der Constraints durch das Oracle stattfindet, wird die Ausführung der Benchmarks ebenfalls durch den \texttt{YarnController} initiiert.
Dazu wird vom \texttt{YarnController} aus für jeden Client die entsprechende Methode aufgerufen, welche ihrerseits den in \autoref{sec:appImplementation} erläuterten \texttt{BenchmarkController} nutzt, um den folgenden Benchmark zu bestimmen und im Falle eines Wechsels des Benchmarks diesen zu starten:

\lstinputlisting[label=lst:hadoopSimulationStartBenchmark,style=cs,
caption={[Auswahl und Start des nachfolgenden Benchmarks]
    Auswahl und Start des nachfolgenden Benchmarks (gekürzt).
    Die Methode \texttt{BenchmarkController.ChangeBenchmark()} ist in \autoref{lst:benchmarkChanging} zu sehen.}]
{./listings/hadoopSimulationStartBenchmark.cs}

Da ein Client auf dem Cluster nur eine Anwendung gleichzeitig ausführt, wird zunächst der zuvor ausgeführte Benchmark abgebrochen.
Bevor der neue Benchmark im Anschluss auf dem Cluster gestartet werden kann, wird zunächst geprüft, ob das Ausgabeverzeichnis der Anwendung im \ac{HDFS} vorhanden ist und gelöscht, da die Anwendung auf dem Cluster andernfalls nicht gestartet werden kann.
Beim Starten der zum Benchmark zugehörigen Anwendung wird zunächst solange gewartet, bis der Anwendung vom \ac{RM} eine \emph{Application ID} zugewiesen wurde, da diese in einer \texttt{YarnApp}"=Instanz sowie in \texttt{Client.CurrentExecutingAppId} gespeichert wird.
Sollte keine \texttt{YarnApp}"=Instanz mehr verfügbar sein, wird stattdessen eine \texttt{OutOfMemoryException} ausgelöst, da während der Simulation keine neuen Instanzen erzeugt werden dürfen (vgl. \autoref{sec:sSharp}).

\subsubsection{Monitoring der ausgeführten Anwendungen}
\label{sec:simulationMonitoring}

Bevor das Monitoring der Anwendungen durchgeführt wird, wird zunächst fünf Sekunden gewartet, bis der \ac{AppMstr} sowie weitere Container der Anwendung allokiert bzw. gestartet wurden.
Diese Wartezeit ist prinzipiell optional, wird hier jedoch genutzt, damit die Auslastung des Clusters besser ermittelt werden kann.
Die Wartezeit vor dem Monitoring ist bereits in der in\autoref{sec:simulationBasics} beschriebenen Mindestdauer eines Schrittes enthalten.

Beim Monitoring werden zunächst die Daten der Nodes, danach die der Anwendungen, ihrer Attempts und zum Abschluss deren Container ermittelt.
Für das Monitoring selbst gib es zwei Ausführungsvarianten.
Die eine Variante liegt darin, dass jede \texttt{IYarnComponent} (also Nodes, Anwendungen, Attempts und Container) jeweils ihre eigenen Daten ermittelt.
Entwickelt wurde diese Variante vor allem für das Monitoring durch die entsprechenden Kommandozeilen"=Befehle.
Die zweite Variante, welche optimal zur Nutzung der REST"=API von Hadoop ist, liegt darin, dass die jeweils übergeordnete Komponente alle Daten für all ihre jeweils untergeordneten Komponenten ermittelt und zur Speicherung übergibt.
Unterschieden werden die beiden Variante durch die Variable \texttt{IYarnComponent.IsSelfMonitoring}:

\lstinputlisting[label=lst:hadoopSimulationMonitoring,style=cs,
caption={[Monitoring der Anwendungen]
    Monitoring der Anwendungen (gekürzt).
    Wenn \texttt{IsSelfMonitoring} auf \texttt{false} gesetzt ist, werden die Daten der Anwendung selbst bereits vom \texttt{YarnController} ermittelt und mithilfe von \texttt{YarnApp.SetStatus} gespeichert, analog zu den Attempts, deren Status hier bereits gespeichert wird.}]
{./listings/hadoopSimulationMonitoring.cs}

Die \texttt{OutOfMemoryException} im vorangegangenen \autoref{lst:hadoopSimulationMonitoring} ist analog zur gleichen Ausnahme beim Starten der Anwendung und wird dann ausgelöst, wenn bereits alle \texttt{YarnAppAttempt}"=Instanzen für diese Anwendung belegt sind.

Das Monitoring der Container bietet eine Besonderheit.
Während bei Anwendungen und Attempts auch die Daten von beendeten Anwendungen ermittelt und gespeichert werden, ist dies bei beendeten Containern nicht der Fall.
Das Monitoring für Container wird nur für zum Zeitpunkt des Monitoring aktive bzw. allokierte Container durchgeführt.
Während bei den Anwendungen und Attempts auch solche, deren Daten ausschließlich beim \ac{TLS} gespeichert sind, ermittelt werden, werden die Daten des \ac{TLS} bei Containern nur als Ergänzung der Daten von derzeit ausgeführten Containern vom \ac{RM} genutzt.
Da Container nur während der der Laufzeit von Anwendungen bzw. Attempts zu deren Ausführung existieren, werden die beim vorherigen Schritt ermittelten Container"=Daten gelöscht, bevor die aktuellen Daten der Container eines Attempts ermittelt werden.

\subsubsection{Validierung durch das Oracle}
\label{sec:simulationOracle}

Im direkten Anschluss an das Monitoring erfolgt die Validierung der Constraints durch das Oracle.
Das Oracle validiert hierbei analog zum Monitoring zunächst die Nodes und danach die Anwendungen, Attempts und Container auf ihre Constraints.
Hierbei wird zunächst überprüft, ob die in \autoref{sec:functionalRequirements} beschrieben funktionalen Anforderungen an Hadoop in Form der in \todo{constraint implementierung} implementierten Constraints für die jeweiligen Komponenten noch erfüllt werden können.
Ist das nicht der Fall, wird dies geloggt und die weiteren Komponenten geprüft.

Das Oracle überprüft auch, ob für das Cluster eine weitere Rekonfiguration möglich ist.
Dies ist dann der Fall, wenn noch mindestens ein Node vorhanden ist, der keine Fehler aufweist und damit den \emph{State} \texttt{Running} hat:

\lstinputlisting[label=lst:hadoopSimulationReconf,style=cs,
caption={Prüfung nach der Möglichkeit weiterer Rekonfigurationen}]
{./listings/hadoopSimulationReconf.cs}

Ist eine Rekonfiguration nicht mehr möglich, wird durch die hierbei ausgelöste \texttt{Exception} die gesamte Simulation abgebrochen.

Zum Abschluss eines Schrittes werden die in \autoref{sec:testRequirements} beschriebenen Behauptungen an das Testverfahren selbst validiert.
Hierbei können jedoch nicht alle Behauptungen in Form von Constraints durch das Oracle automatisch während der Ausführung validiert werden.
Von den implementierten Constraints können zudem nicht alle direkt innerhalb des Modells während der Ausführung eines Simulations"=Schrittes validiert werden, weshalb außerhalb der Simulation ebenfalls Constraints definiert sind, die zum Abschluss der Simulation geprüft werden (vgl. \todo{constraint implementierung}).

\subsubsection{Ausgaben während eines Schrittes}
\label{sec:simulationStepOutput}

Die wesentlichen Ausgaben während eines Tests wurden bereits in \autoref{sec:dataOrganisation} definiert und beschrieben.
Neben diesen Daten werden im Programmlog weitere Daten gespeichert, damit die Ausführung eines Testfalles besser nachvollzogen werden kann.
Zudem werden alle Ein"= und Ausgabedaten der SSH"=Verbindungen zwischen dem Modell und dem realen Cluster in einer eigenen Log"=Datei gespeichert.
Dieses SSH"=Log dient dazu, die Ursache von unerwarteten Fehlern herauszufinden.

Neben den bereits beschriebenen Daten werden im Programmlog folgende Daten gespeichert:

\begin{itemize}
    \item Verbundene SSH"=Verbindungen mit ihrer ID zur besseren Zuordnung im SSH"=Log
    \item Ausführung der Erstellung von vorab generierten Eingabedaten
    \item Vollständiger Pfad des Setup"=Scriptes (vgl. \autoref{sec:realCluster})
    \item URL des Controllers zur Nutzung der REST"=API
    \item Vorschau auf bzw. derzeit vom \texttt{BenchmarkController} ausgewählte Benchmarks
    \item Ausführung von Komponentenfehlern
    \item Diagnostik"=Daten der YARN"=Komponenten
    \item Welche Constraints bei welchen Komponenten verletzt wurden
    \item Die Information, wenn eine Rekonfiguration nicht möglich ist (vgl. \autoref{lst:hadoopSimulationReconf})
\end{itemize}

Nach Abschluss der Simulation wird ein erneutes Monitoring des gesamten Clusters durchgeführt und der hierbei ermittelte Status als finaler Clusterstatus ausgegeben.
Zudem werden einige statistische Kenndaten zur Simulation ausgegeben:

\begin{itemize}
    \item Gesamtdauer der Simulation
    \item Anzahl erfolgreicher Schritte
    \item Anzahl der maximal möglichen, aktivierbaren Komponentenfehler
    \item Anzahl aktivierter und deaktivierter Komponentenfehler
    \item Letzter ermittelter \ac{MARP}"=Wert
    \item Anzahl aller ausgeführten, erfolgreicher, nicht erfolgreicher sowie abgebrochener Anwendungen
    \item Anzahl aller ausgeführten Attempts
    \item Anzahl aller während der Ausführung erkannten Container
    \item Anzahl aller validierten Constraints und fehlerhaften Constraints, getrennt nach \ac{SuT}- und Testsystem"=Constraints
\end{itemize}

Ein möglicher Programmlog sowie das exakte Ausgabeformat für eine Ausführung eines Testfalls findet sich in \autoref{app:outputFormat}.

\subsection{Weitere mit der Simulation zusammenhängende Methoden}
\label{sec:simulationUtilities}

Neben der Ausführung der Simulation mit und ohne der Möglichkeit zur Aktivierung der Komponentenfehler gibt es noch einige weitere Methoden, die mit der Simulation zusammenhängen.
Darüber besteht die Möglichkeit, die vorab generierten Eingabedaten für die Simulation, ohne die Simulation selbst auszuführen, zu generieren.
Da die Generierung der Eingabedaten nur dann durchgeführt wird, wenn die Verzeichnisse im \ac{HDFS} noch nicht vorhanden sind (und somit auch die Daten selbst nicht), besteht auch die Möglichkeit, die bestehenden Eingabedaten zu löschen und anschließend neu zu geniereren \todo{vgl. abschnitt benchcontroller damit und dann evtl. neu formulieren}.
Zudem kann die Simulation der durch den \texttt{BenchmarkController} ausgewählten Benchmarks direkt und ohne die Ausführung der gesamten Simulation durchgeführt werden:

\lstinputlisting[label=lst:hadoopSimulationBenchmarks,style=cs,
caption={Simulation der auszuführenden Benchmarks}]
{./listings/hadoopSimulationBenchmarks.cs}
