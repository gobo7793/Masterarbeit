\section{Auswahl der Testkonfigurationen}
\label{sec:selectTestcases}

Die im in \autoref{subsec:testcaseGeneration} beschriebenen Testkonfigurationen werden mithilfe verschiedener Variablen implementiert.
Anhand dieser Konfiguration wurden dynamisch zur Laufzeit die entsprechenden Testfälle generiert, wobei jeder Simulations"=Schritt des \ac{ss}"=Simulators einem Testfall entspricht.

Relevant für die Ausführung einer Konfigurationen sind folgende, bereits in \autoref{lst:hadoopSimulationInit} gezeigte, Eigenschaften:

\lstinputlisting[label=lst:hadoopTest,style=cs,linerange={2-2,6-10},
caption={Zur Definition einer Testkonfiguration relevante Felder}]
{./listings/hadoopSimulationInit.cs}

Da die jeweiligen Auswirkungen der Eigenschaften bereits in \autoref{subsec:simulationModelInit} erläutert wurden, wird an dieser Stelle hierauf verweisen.

Zur Festlegung dieser Variablen und damit der Testkonfigurationen wurde zunächst eine Systematik entwickelt, nach welcher die Testfälle durchgeführt werden.
Hierfür wurden mithilfe des folgenden Programmcodes zunächst zwei Seeds ermittelt:

\lstinputlisting[label=lst:generateTestCaseSeeds,style=cs,
caption={Ermittlung der für die Testkonfigurationen genutzten Basisseeds}]
{./listings/generateTestCaseSeeds.cs}

Die beiden ermittelten Seeds 0xAB4FEDD und 0x11399D3 wurden jeweils bei jeder Konfiguration zwischen den anderen Variablen genutzt.

Zur Festlegung der Werte zur generellen Wahrscheinlichkeiten zur Aktivierung bzw. Deaktivierung von Komponentenfehlern wurden zunächst über 20.000 mögliche Aktivierungen und Deaktivierungen mit verschiedenen generellen Wahrscheinlichkeiten und Auslastungsgraden der Nodes simuliert.
Der dabei für alle Konfigurationen ausgewählte Wert von 0,3 stellt hierbei eine ausgewogene Aktivierung bzw. Deaktivierung der Komponentenfehler bei unterschiedlichen Auslastungsgraden der Nodes dar.

Die Anzahl der Hosts wurde bei einigen Konfigurationen auf 1 festgelegt, bei den meisten liegt diese jedoch bei 2.
Die Node"=Basisanzahl wurde auf 4 festgelegt, da hierbei das Cluster eine ausreichende Größe besitzt und jedem Node ausreichend Ressourcen zur Verfügung stehen, um Anwendungen auszuführen.
Bei einer zu hohen Basisanzahl erhält jeder einzelne Node geringere Ressourcen, was vor allem die Ausführung bei ressourcenintensiven Anwendungen wie \zB \acl{pt} behindert, während bei einer zu geringen das Cluster sehr klein ist und daher keine ausreichende Evaluationsbasis bietet.
Die Anzahl der Simulations"=Schritte und damit der ausgeführten Testfälle selbst wurde variiert, wodurch in einigen Konfigurationen 5 und in anderen 10 Testfälle ausgeführt werden.
Ebenso variiert wurde die Anzahl der simulierten Clients, , die im Bereich von 2, 4 oder 6 Clients liegt.

Alle Konfigurationen wurden mindestens einmal jeweils mit der Selfbalancing"=Komponente ohne Mutationen sowie in einem der in \autoref{sec:implMutationTests} erläuterten Mutationsszenarien ausgeführt.
Von den hiermit möglichen 48 Testkonfigurationen wurden die möglichen Konfigurationen mit einem Host und sechs simulierten Clients sowie die möglichen Konfigurationen mit zwei simulierten Clients und zehn Testfällen nicht ausgeführt.
Das ergibt für die Evaluation somit eine Datenbasis von 32 grundlegenden Testkonfigurationen.
Eine Übersicht der genutzten Testkonfigurationen und der Dauer der jeweiligen Tests ist in \autoref{app:overviewExecutedTestCases} zu finden.

Bei der Ausführung der Tests zur Evaluation wurden Eingabedaten nicht vorab generiert, sondern während der Ausführung von den Anwendungen direkt generiert.
Daher wurde die Mindestdauer für einen Simulations"=Schritt in allen Fällen auf 25 Sekunden festgelegt, da hierbei ein Großteil der ausgeführten Anwendungen auf dem Cluster erfolgreich beendet werden können.
Eine Ausreichende Mindestdauer ist vor allem für die Generierung der Eingabedaten für nachfolgende Anwendungen wichtig, da nicht vollständig generierte Daten von abgebrochenen Anwendungen nicht von nachfolgenden Anwendungen genutzt werden können.
Zudem stellt dies eine ausreichende Zeitspanne zur Rekonfiguration von Hadoop dar.
