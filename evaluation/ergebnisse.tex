\section{Erkenntnisse der Evaluation}
\label{sec:evaluationResults}

\todo{Zusammenfassung, hier erwähnen, dass MUT schneller und weniger failapps hatte?}
\todo{Mehr auf Anforderungen verweisen}
\todo{das heißt defekte nodes!!11}

\subsection{Betrachtung der \ac{MARP}"=Werte}
\label{sec:marpValueResults}

Bei der Betrachtung der \ac{MARP}"=Werte lässt sich generell sagen, dass die Selfbalancing"=Komponente den \ac{MARP}"=Wert entsprechend der Auslastung des Clusters anpasst.
Während bei allen Testkonfigurationen, bei denen alle 4 Mutationen aktiv waren, der \ac{MARP}"=Wert unverändert blieb, wurde er bei 16 von 20 Ausführungen der 16 Konfigurationen ohne Mutationen verändert:

\begin{table}[h]
    \begin{tabular}{l|c|c|c|c|c|c|c|c|c|c}
    	Konf. &  1.1  &  1.2  &   3   &  5.1  &  5.2  &  7.1  &  7.2  &  9.1  &  9.2  &  11   \\ \hline
    	Wert  & 0,100 & 0,100 & 0,474 & 0,242 & 0,100 & 0,100 & 1,000 & 0,269 & 0,175 & 0,539 \\
    	\multicolumn{11}{c}{} \\
    	Konf. &  13   &  15   &  17   &  19   &  21   &  23   &  25   &  27   &  29   &  31   \\ \hline
    	Wert  & 0,356 & 0,368 & 0,731 & 0,430 & 0,335 & 0,498 & 0,521 & ,0819 & 0,273 & 0,333
    \end{tabular}
    \caption{Finale \ac{MARP}"=Werte der Testkonfigurationen ohne Mutanten}
    \label{tab:finalMarpValues}
\end{table}

Da er in den Konfigurationen 1 und 7 bei der jeweils ersten Ausführung nicht verändert wurde, wurden beide Konfigurationen erneut ausgeführt, wobei der \ac{MARP}"=Wert bei letzterem mehrmals erhöht wurde, bevor er im finalen Clusterstatus auf 1 gesetzt wurde.
Bei der Konfiguration 1 wurde der Wert dagegen bei keiner der beiden Ausführungen verändert.

Die nicht durchgeführte Änderung des \ac{MARP}"=Wertes in Konfiguration 1 liegt sehr wahrscheinlich daran, dass in hier nur im ersten der fünf Testfälle zwei Anwendungen gleichzeitig gestartet werden.
Dadurch wurden in allen 10 Testfällen zusammen nur 8 Anwendungen gestartet, die Hälfte davon jeweils beim ersten Testfall.
Da zudem 4 der 8 Anwendungen nur kleine Anwendungen (\acl{rtw} und \acl{pi}) sind und diese entsprechend schnell beendet werden können, steht den wesentlich ressourcenintensiveren Anwendungen \acl{dfw} und \acl{dfr} das gesamte Cluster nahezu exklusiv zur Verfügung.
Daher stehen den Anwendungen ausreichend Ressourcen zur Verfügung, was eine Anpassung des \ac{MARP}"=Wertes unnötig erscheinen lässt und daher durch die Selfbalancing"=Komponente nicht durchgeführt wird.

Bei der Testkonfiguration 7 ist dies ähnlich, wobei die gesamte Last auf mehr Nodes verteilt werden kann.
Der Test 7.2 und der hier deutlich veränderte \ac{MARP}"=Wert im Vergleich zu Test 7.1 ohne Anpassung zeigt jedoch auch, dass es stark abhängig davon ist, wie die Last im Cluster verteilt wird.
Bestätigt wird dies durch die Tests 9.1 und 9.2, da bei letzterem weniger Komponentenfehler injiziert wurden und sich die Last entsprechend besser verteilen konnte.
Dadurch war im Test 9.2 ein um rund 0,1 niedrigerer \ac{MARP}"=Wert als im Test 9.1 nötig.

Auffällig war zudem, dass der \ac{MARP}"=Wert in den Testausführungen 7.2, 9.1 und 23 nicht direkt im ersten Testfall verändert wurde, sondern erst bei der Ausführung von Testfällen im späteren Verlauf der jeweiligen Tests.
Als Resultat wurde daher in 9 der 15 Testfälle zunächst das hierfür genutzte Constraint als ungültig validiert.

\subsection{Erkennung der Mutanten}
\label{sec:killingMutants}

Da die Selfbalancing"=Komponente den \ac{MARP}"=Wert basierend auf der aktuellen Auslastung des Clusters anpasst, konnte anhand der Betrachtung der \ac{MARP}"=Werte auch geprüft werden, ob die implementierten Mutationen vom Testsystem erkannt wurden.
Um das zu bewerkstelligen wurden von den 16 Testkonfigurationen mit einem Mutationsszenario 22 Testausführungen durchgeführt (vgl. \autoref{app:overviewExecutedTestCases}).

Zunächst wurde das Mutationsszenario genutzt, in dem alle vier Mutationen enthalten sind (vgl. \autoref{sec:implMutationTests}).
Bei jeder der 17 Testausführungen mit allen Mutanten wurden diese basierend auf dem Constraint zur Erkennung des \ac{MARP}"=Wertes erkannt.
Eine Besonderheit bildet hier jedoch der Test 2, der den korrespondierenden Mutationstest zur Konfiguration 1 darstellt, bei der bei beiden Ausführungen der \ac{MARP}"=Wert nicht verändert wurde.
Bei Test 2 kann daher nicht eindeutig festgestellt werden, ob der Mutant erkannt wurde, oder ob aufgrund der gestarteten Anwendungen der \ac{MARP}"=Wert nicht verändert wurde (vgl. Vermutungen zu Testkonfiguration 1 in \autoref{tab:finalMarpValues}).

Anders ist dies im Vergleich der Ausführungen der Testkonfigurationen 7 und 8.
Durch die massive Veränderung des \ac{MARP}"=Wertes im Test 7.2 auf den finalen Wert von 1 kann davon ausgegangen werden, dass die Mutanten der Konfiguration 8 erkannt wurden.
Dies wird dadurch gestützt, dass bei Konfiguration 8 im Gegensatz zur korrespondieren Testkonfiguration 3 der 4 gestarteten Anwendungen gefailt sind.
Zudem stellt das ein Indiz dafür dar, dass der Mutant in Konfiguration 2 erkannt worden sein könnte.

Während bei jeder Konfiguration ein Mutationsszenario mit jeweils allen vier Mutanten genutzt wurde, wurde die Testkonfiguration 10 zusätzlich mit jeweils einem Mutanten ausgeführt.
Ziel hierbei war es zu validieren, ob einzelne Mutanten ebenfalls vom Testsystem erkannt werden oder zur Erkennung der Mutanten vom Testsystem eine Kombination aus mehreren Mutaten nötig ist.
Hierzu wurde die Testkonfiguration 10 mit unterschiedlichen Mutationsszenarien der Plattform Hadoop"=Benchmark ausgeführt, bei denen jeweils ein Mutant aktiv ist.
Die Auswahl dieser Testkonfiguration hierfür liegt darin begründet, dass hier das Cluster auf beiden Hosts mit sechs Nodes gestartet wird, auf denen bis zu vier Anwendungen gleichzeitig gestartet werden.
Zudem wurde beim Test 9.2 festgestellt, dass sich der \ac{MARP}"=Wert auch direkt im ersten ausgeführten Testfall ändern kann und es gab bei den Ausführungen der Konfiguration 9 keine weiteren ungültigen Constraints als fehlerhafte Anwendungen.

Einige Ergebnisse der hierfür 5 ausgeführten Tests sind sehr unterschiedlich.
So variiert die Anzahl der aktivierten und deaktivierten Komponentenfehler zwischen 7 und 11 bzw. 5 und 9, sowie die Anzahl der gefailten Anwendungen zwischen 1 und 3.
Gemein haben alle Tests jedoch, dass der \ac{MARP}"=Wert bei allen 5 Tests nicht verändert wurde, womit alle Mutationen erkannt wurden.
Damit kann festgestellt werden, dass jeder der vier in \autoref{sec:implMutationTests} beschriebenen Mutanten durch das entwickelte Testsystem erkannt wird.

\subsection{Aktivierung und Deaktivierung der Komponentenfehler}
\label{sec:faultInjectionEval}

Die Aktivierung und Deaktivierung der Komponentenfehler in einem Testfall hängt neben dem zur Berechnung benötigtem Seed vor allem von den zuvor ausgeführten Testfällen einer Testkonfiguration ab (vgl. \autoref{sec:simulationFaultActivation}).
Daher werden abhängig von der Lastverteilung im Cluster auch bei einer mehrmaligen Ausführung der gleichen Konfiguration \uU unterschiedliche Komponentenfehler aktiviert.
Unterschieden werden muss hierbei zudem zwischen aktivierten und injizierten Komponentenfehlern.
Während beide implementierten Komponentenfehler für einen Node in einem Testfall auch gleichzeitig aktiviert werden konnten, wurde gemäß \todo{Abschnitt mit Komponentenfehler im Node} in so einem Fall jedoch nur der \texttt{NodeDead}"=Fehler im Cluster injiziert.
Die Deaktivierung bzw. das Reparieren der Komponentenfehler verhält sich analog hierzu.

Im Vergleich zwischen korrespondierenden Konfigurationen, die sich nur in der Nutzung des Mutationsszenarios unterschieden, wurde nur 5 mal die gleiche Anzahl an Komponentenfehler aktiviert, bei der Deaktivierung der Komponentenfehler besitzen nur 3 korrespondierende Konfigurationen die gleiche Anzahl.
Die Anzahl der aktivierten und deaktivierten Komponentenfehler unterschied sich dagegen in 8 bzw. 7 korrespondierenden Testkonfigurationen um jeweils einen Komponentenfehler.
In allen anderen Ausführungen von korrespondierenden Konfigurationen unterschied sich die Anzahl um jeweils mehr als einen Komponentenfehler.
Mit 20 aktivierten Komponentenfehlern wurden bei der Ausführung der Testkonfiguration 32 die meisten aktiviert, die meisten Komponentenfehler deaktiviert wurden bei den Konfigurationen 11 und 12 mit jeweils 15 Stück.
Nur im Test zur Konfiguration 2 wurden mit 3 Stück alle aktivierten Komponentenfehler während der Simulation auch wieder deaktiviert.
In den Tests 4, 5.1, 5.2 und 6 wurden jeweils 6 oder 7 Komponentenfehler aktiviert, jedoch keine deaktiviert, weshalb diese Tests bereits beim 3. ausgeführten Testfall gemäß \autoref{sec:simulationOracle} abgebrochen wurden.

Im Vergleich zwischen den Tests von korrespondierenden Testkonfigurationen sind die Tests der Konfigurationen 1 und 2 auffällig.
Während beim Test 1.1 mit 5 Komponentenfehlern bzw. beim Test 1.2 mit 7 Komponentenfehlern jeweils rund jeder achte mögliche Komponentenfehler aktiviert wurde, wurden beim Test 2 lediglich 3 Komponentenfehler für 4 Nodes in 5 Testfällen (insgesamt also 40 mögliche Komponentenfehler) aktiviert.
Eine geringere Quote weist lediglich Test 9.2 auf, bei dem mit 4 von 60 möglichen Komponentenfehler nur 7 \% aktiviert wurden.
Die Testkonfiguration 9 ist auch deshalb auffällig, da im Test 9.1 fast dreimal so viele Komponentenfehler, also 11 Stück, aktiviert wurden.
Auch in den korrespondierenden Tests der Konfiguration 10 liegt die Anzahl der aktivierten Komponentenfehler mit 7 bis 11 jeweils mehr als doppelt so hoch wie in Test 9.2.

Auffällig ist zudem, dass bei korrespondierenden Testkonfigurationen mit unterschiedlicher Anzahl an aktivierten Komponentenfehlern die niedrigere Anzahl meist die Mutationstests aufweisen.
Nur bei den Tests 27 und 28.1 sowie bei den Tests 31 und 32 weisen die Tests ohne Mutationsszenario die niedrigere Anzahl auf.
\todo{auf diskussion der selfbalancing komponenten verweisen als grund}

\subsection{Nicht vollständig abgeschlossene Anwendungen}
\label{sec:failedAppsEval}

Wie bereits erwähnt, sind rund ein viertel aller gestarteten Anwendungen gefailt, was im Schnitt 2,4 Anwendungen pro ausgeführten Test ergibt.
Die meisten gefailten Anwendungen sind hierbei mit 9 bzw. 8 bei den Tests 31 und 32 zu finden.
Auffällig ist zudem der Vergleich zwischen den Tests 19 und 20.
Während bei der Ausführung der Testkonfiguration 19 ganze 5 Anwendungen gefailt sind, ist bei der Ausführung des Tests 20 keine einzige gefailt.
Auffallend ist zudem, dass bei Konfigurationen mit Mutationsszenario fast immer weniger oder gleich viele Anwendungen gefailt sind als bei den korrespondierenden Konfigurationen ohne Mutationsszenario.
Eine Ausnahme bildet der Test 8, bei dem 3 Anwendungen gefailt sind, während bei den Tests 7.1 und 7.2 jeweils keine Anwendung gefailt ist.
Eine weitere Ausnahme bildet der Test 9.2, bei dem eine Anwendung mehr gefailt ist als im Test 10.3, die restlichen Tests der Konfigurationen 9 und 10 verhalten sich jedoch wie andere korrespondierende Testkonfigurationen.

Bei der Betrachtung der Constraints, welche die in \autoref{sec:clusterRequirements} definierte Anforderung umsetzen, dass Anwendungen vollständig ausgeführt werden, solange sie nicht manuell bzw. durch das Testsystem vorzeitig abgebrochen werden, fällt auf, dass die Anzahl der ungültigen Validierungen durch das Oracle mit kumuliert 317 ungültigen Constraints mehr als die Hälfte aller ungültigen Constraints ausmacht (58,6 \% ).
Im Schnitt ergibt das somit 7,5 ungültige Constraints pro Test bzw. 1,4 ungültige Constraints pro durch das Oracle überprüften Testfall.
Die auf den ersten Blick sehr hohe Anzahl an ungültigen Constraints resultiert daraus, dass eine gefailte Anwendung bei jedem nachfolgenden Testfall bei einer Testausführung erneut durch das Oracle entsprechend validiert wurde.
Aussagekräftiger ist daher die Anzahl von 102 nicht vollständig abgeschlossenen Anwendungen.

Anhand der Datenbasis lassen sich vier Ursachen für nicht vollständig ausgeführte Anwendungen ausmachen:

\begin{itemize}
    \item
        Der \ac{AppMstr} ist nicht mehr erreichbar, da der auszuführende Node aufgrund eines Komponentenfehlers nicht mehr erreichbar ist und der \ac{AppMstr} nach einiger Zeit mit dem Fehler \emph{\ac{AppMstr}"=Timeout} als abgebrochen markiert wird.
    \item
        Die den \ac{AppMstr} zugewiesenen Nodes sind vollständig ausgelastet, wodurch der \ac{AppMstr} selbst nicht ausgeführt werden kann und dieser nach einiger Zeit mit dem Fehler \emph{\ac{AppMstr}"=Timeout} abgebrochen wird.
        Dies beinhaltet auch Timeouts, wenn einem \ac{AppMstr} keine Ressourcen in Form eines ausführenden Nodes zugewiesen werden können.
    \item
        Während der Ausführung einer \ac{MR}"=Anwendung wird ein Fehler im Map"=Task festgestellt, der dazu führt, dass der Task abgebrochen wird.
        Dieser Fehler kam bei den hier ausgeführten Tests lediglich bei der Anwendung \acl{dfr} vor, wenn die zuvor generierten Eingabedaten für diesen Benchmark aufgrund aktivierter Komponentenfehler nicht mehr im Cluster vorhanden waren.
        Zwar werden Dateien im \ac{HDFS} immer auf mehr als einem Node gespeichert (vgl. \autoref{sec:hadoop}), jedoch ist es möglich, dass die für die Anwendung benötigten Daten auf Nodes repliziert wurden, die alle beendet wurden.
        Dies führte dazu, dass die benötigten Daten nicht gefunden werden können bzw. bereits im \ac{HDFS} als fehlerhaft markiert sind.
        Dadurch wird im Map"=Task ein Fehler ausgelöst, der die gesamte Anwendung vorzeitig beendet.
    \item
        Der \ac{AppMstr} eines Attempts wird mit dem Exitcode -100 beendet.
        Dieser Fehler kommt dann vor, wenn versucht wird, einen Anwendungs"=Container für den jeweilige Anwendung bzw. Attempt auf einem defekten Node zu starten.
        Dieser Fehler trat nur dann auf, wenn im ausführende Node des betroffenen \ac{AppMstr} im gleichen Testfall ein Komponentenfehler injiziert wurde und der Node dadurch aufgrund des Defektes ausfiel.
        Aufgrund der mit dem Fehler verbundene Fehlermeldung \enquote{Container released on a *lost* node} liegt die Vermutung nahe, dass Anwendungs"=Container, hier wahrscheinlich der \ac{AppMstr}, zum Zeitpunkt der Fehlerinjizierung bereits abgeschlossen waren und das Cluster bereits die benötigten Ressourcen wieder freigegeben hat.
        Da dies jedoch nicht möglich war, wurde der \ac{AppMstr} mit dem entsprechenden Fehler beendet.
    
\end{itemize}

Hierbei werden aufgrund eines \ac{AppMstr}"=Timeouts zunächst nur die Attempts mit dem entsprechenden Fehler abgebrochen, nicht jedoch die Anwendung selbst.
Die Anwendung selbst wird in so einem Fall erst dann als gefailt abgebrochen, sobald zwei Attempts aufgrund eines Timeouts abgebrochen werden mussten.
Wenn ein Attempt mit dem Exitcode -100 terminiert, wird unabhängig von zuvor ausgeführten Attempts ein erneuter Attempt mit entsprechendem \ac{AppMstr} gestartet.

Bei einigen der \ac{AppMstr}"=Timeouts aufgrund der Aktivierung von Komponentenfehler lässt sich zudem ein spezielles Muster erkennen.
Hierbei wurde in einem zuvor ausgeführten Testfall regulär auf einem Node ein \ac{AppMstr} einer Anwendung allokiert.
Nun kann es passieren, dass für diesen Node ein Komponentenfehler injiziert wird, was dazu führt, dass der Node nicht mehr erreichbar ist und der \ac{AppMstr} aufgrund eines Timeouts als beendet markiert wird.
Hierbei wird direkt im Anschluss ein neuer \ac{AppMstr} allokiert, was auch dazu führt, dass die Anwendung nun einen zweiten Attempt besitzt, nachdem der erste aufgrund des Timeouts abgebrochen wurde.
Nun kann es dabei passieren, dass dies noch während der Aktivierung von Komponentenfehlern innerhalb eines Simulations"=Schrittes geschieht, wodurch es möglich ist, dass der auszuführende Node des zweiten \ac{AppMstr} ebenfalls aufgrund eines im gleichen Testfall injizierten Komponentenfehlers nicht mehr erreichbar ist.
Dadurch wird der zweite \ac{AppMstr} bzw. Attempt aufgrund des Timeouts vorzeitig als abgebrochen markiert und die gesamte Anwendung dadurch abgebrochen.

\subsection{Rekonfiguration des Clusters nicht möglich}
\label{sec:noReconfig}

\todo{Cluster nicht mehr rekonfigurieren auch in Anforderungen}
Insgesamt 13 der 42 ausgeführten Tests wurden vorzeitig abgebrochen, da eine Rekonfiguration des Clusters nicht möglich war.
Dies entspricht dem in \autoref{sec:simulationOracle} definierten Verhalten und in \autoref{sec:predictions} gefordertem Verhalten, wenn alle Node im Cluster defekt sind.
Im Folgenden wird für die betroffenen Testkonfigurationen und Tests betrachtet, weshalb es dazu kam.

\subsubsection{Testkonfigurationen 3 bis 6}
\label{sec:noReconf36}

Erstmalig ist ein Abbruch im Test 4 aufgetreten, auch die weiteren korrespondierende Tests der Konfigurationen 5 und 6 wurden abgebrochen.
Hier waren bereits beim 3. Testfall alle verfügbaren Nodes beendet, was auffällig ist, vor allem da damit die Hälfte der Tests mit dem ersten Seed und dem Cluster auf einem Host vorzeitig abgebrochen wurden.
Dies liegt einerseits daran, dass im Gegensatz zu den beiden Konfigurationen mit nur zwei Clients hier bis zu vier Anwendungen gleichzeitig gestartet werden, was die Last auf den Nodes deutlich erhöht.
In Test 3, welcher somit theoretisch ebenfalls abgebrochen werden hätte müssen, wurden 11 Anwendungen im Cluster gestartet.
Dies liegt an der geringeren Auslastung eines einzelnen Nodes im Gegensatz zu den anderen Tests.
In den abgebrochenen Tests hatte Node 4 im ersten Testfall eine hohe bzw. sehr hohe Auslastung, im Test 3 jedoch nur eine mittlere.
Diese mittlere Auslastung reichte jedoch aus, um den Node im ausgeführten 3. Testfall gemäß \todo{deaktivieren von komponentenfehler} wieder zu aktivieren, während die anderen noch aktiven Nodes spätestens in diesem Testfall einen Komponentenfehler injiziert bekamen.
Durch diesen einen nun weiterhin ausgeführten Node ist es dem Cluster daher möglich gewesen, sich im Test 3 zu rekonfigurieren.

\subsubsection{Testkonfigurationen 15 und 16}
\label{sec:noReconf1516}

Die Ausführung der Tests 13 bzw. 14 und 15 bzw. 16 unterscheidet sich nur in der Anzahl der Testfälle der jeweiligen Testkonfiguration.
Dementsprechend wurden die äquivalenten Tests 13 und 14 im Gegensatz zu den beiden anderen vollständig ausgeführt, da der Abbruch der Tests 15 und 16 im sechsten ausgeführten Testfall stattfand.
Die Nodes hatten in den vier Tests folgende Auslastung:

\begin{table}[h]
    \begin{tabular}{c|cccc}
    	        Test          & 13 & 14 & 15 & 16 \\ \hline
    	  Fehlerhafte Nodes   & 2  & 2  & 3  & 1  \\
    	Auslastung in Prozent & 47 & 97 & 96 & 98
    \end{tabular}
    \caption[Status der Nodes im fünften Testfall der Tests 13 bis 16]
        {Status der Nodes im fünften Testfall der Tests 13 bis 16.
        Der Wert der Auslastung ist die kumulierte Auslastung aller noch aktiven Nodes.}
    \label{tab:loadTests1316}
\end{table}

Bei den beiden betroffenen Tests 15 und 16 sehr hohe Auslastung der noch aktven Nodes im 5. Testfall führte im darauf folgenden Testfall dazu, dass bei allen noch aktiven Nodes ein Komponentenfehler aktiviert wurde.
Daher wurden die beiden Tests im jeweils 6. ausgeführten Testfall abgebrochen.

\subsubsection{Testkonfigurationen 19 bis 22}
\label{sec:noReconf1922}

Bei den Konfigurationen 19 bis 22 verhält es sich ähnlich wie bei den Konfigurationen 3 bis 6.
Analog dazu wurde auch Test 19 nicht vorzeitig abgebrochen, die Tests 20 bis 22 im vierten Testfall dagegen schon.

Alle vier Tests haben gemeinsam, dass im jeweils dritten Testfall lediglich Node 1 inaktiv ist.
Bei den beiden Tests ohne Mutationsszenario wurde hierbei jeweils die Verbindung zum Node im Testfall zuvor getrennt, bei den Mutationstests wurde der Node durch einen Komponentenfehler beendet.
Dies liegt in der Historie des Nodes innerhalb des Tests begründet:

\begin{table}[h]
    \begin{tabular}{c|cccc}
    	   Test    &                19                 &             20             &                21                 &             22             \\ \hline
    	Testfall 1 &               93 \%               &            0 \%            &              100 \%               &            0 \%            \\
    	Testfall 2 & \makecell{Verbindung \\ getrennt} &          100  \%           & \makecell{Verbindung \\ getrennt} &           93  \%           \\
    	Testfall 3 &                 -                 & \makecell{Node \\ beendet} &                 -                 & \makecell{Node \\ beendet} \\
    	Testfall 4 &   \makecell{Verbunden \\ 93 \%}   &             -              &         \emph{Verbunden}          &             -
    \end{tabular} 
    \caption{Auslastungen und injizierte Komponentenfehler in Node 1 in den Tests 19 bis 22}
    \label{tab:loadNode1Tests1922}
\end{table}

Die Aktivierung und Deaktivierung der Komponentenfehler in den anderen Nodes ist in allen Tests gleich und daher zur Ermittlung der Gründe des Abbruchs der Testausführung nicht relevant.
Durch die unterschiedliche Auslastungen in den Testfällen 1 der Tests zwischen Tests ohne Mutationen (19 und 21) und mit Mutationen (20 und 22) wurden unterschiedliche Komponentenfehler aktiviert.
Dies führte dazu, dass der relevante Node 1 bei den Mutationsstests nicht gestartet wurde, während die anderen Nodes beendet wurden wie in den Tests 19 und 21.

Eine Besonderheit bildet hier zudem Test 21, bei dem der Komponentenfehler vom Testsystem deaktiviert wurde, jedoch nicht repariert werden konnte.
Dies liegt darin, dass der Docker"=Container nicht mit dem Docker"=Netzwerk verbunden werden konnte.
Aus diesem Grund wurde vom Oracle bei der Prüfung der Rekonfigurierbarkeit des Clusters der Test entsprechend beendet, da der Node nicht verbunden war.
Zwar wurde der Fehler von Docker nicht absichtlich oder durch das Testsystem herbeigeführt, jedoch zeigt dies auch, dass der Fehler ebenfalls erkannt werden konnte.

\subsubsection{Testkonfigurationen 27 und 28}
\label{sec:noReconf2728}

In den beiden Tests 28.1 und 28.2 wird der Test im 8. Testfall abgebrochen, während Test 27 nach allen 10 Testfällen regulär beendet wird.
Das liegt daran, dass im 8. Testfall bei den beiden Mutationstests in fünf der sechs Nodes ein Komponentenfehler injiziert wird, von Node 1 wird die Verbindung getrennt, die Nodes 3 bis 6 komplett beendet.
Im Test 27 ohne Mutationsszenario wird dagegen zwar auch die Verbindung von Node 1 getrennt, aber zusätzlich nur Node 3 beendet, sodass die Nodes 4 bis 6 weiterhin aktiv sind.
Node 2 wird in allen drei Tests bereits im 3. Testfall beendet, da die Auslastung des Nodes im 2. Testfall bei jeweils über 90 Prozent liegt.
Die übrigen der 19 bzw. 20 aktivierten und zwischen 10 und 13 wieder deaktivierten Komponentenfehlern unterschieden sich in den drei Tests bis auf einzelne, hier nicht relevante, Ausnahmen nicht.

Der Grund für die Injizierung von Komponentenfehlern bei noch allen aktiven Nodes im 8. Testfall liegt in der Auslastung der Nodes im 7. Testfall.
Diese beträgt im Test 27 ohne Mutationen bei den beiden betroffenen Nodes bei jeweils 100 Prozent, bei den übrigen Nodes ist jedoch keine bzw. eine geringe Auslastung vorhanden.
In den beiden Tests der Konfiguration 28 ist das Cluster jeweils vollständig Ausgelastet, wodurch die Wahrscheinlichkeit zur Aktivierung der Komponentenfehler im folgenden Testfall stark ansteigt.
Dadurch war es möglich, dass alle noch aktiven Nodes vom Cluster getrennt bzw. beendet wurden und der Test aufgrund fehlender Rekonfigurationsmöglichkeiten abgebrochen wurde.

\subsubsection{Testkonfigurationen 31 und 32}
\label{sec:noReconf3132}

Die beiden Tests 31 und 32 verliefen beide ähnlich zueinander.
Die hohe Anzahl der 19 bzw. 20 aktivierten Komponentenfehler reichten bei jeweils 11 wieder deaktivierten Fehlern aus, um die beiden Tests im 8. Testfall zu beenden.

Besonders war hier, dass es bei jeweils mehreren Testfällen vorgekommen ist, dass mehr als 3 Komponentenfehler aktiviert bzw. deaktiviert wurden.
So kam es vor, dass \zB in 3. Testfall bereits eine Rekonfiguration nur deshalb möglich war, weil der zuvor vom Cluster getrennte Node 1 wieder mit dem Cluster verbunden wurde, während die Nodes 2 und 4 bis 6 anderen Nodes getrennt oder beendet wurden, Node 3 wurde bereits im Testfall zuvor beendet.
Dies trifft auch auf die beiden korrespondierenden Konfigurationen 29 und 30 zu, bei denen nur fünf Testfälle ausgeführt wurden.

Bis auf den beendeten Node 2 wurden spätestens im 6. ausgeführten Testfall die im 3. Testfall injizierten Komponentenfehler wieder repariert.
Zwar wurde im 7. Testfall je ein Komponentenfehler repariert, jedoch im Test ohne Mutationen auch ein weiterer injiziert.
In Kombination mit den drei bzw. vier aktivierten Komponentenfehlern in Testfall 8 führte das daher dazu, dass kein aktiver Node im Cluster mehr vorhanden war und der Test entsprechend abgebrochen wurde.

\subsection{Nicht erkannte oder gespeicherte Daten des Clusters}
\label{sec:notDetectedData}

Einige Daten des Clusters wurden nicht im Testsystem gespeichert bzw. im Programmlog ausgegeben.
Dies verstößt damit gegen die in \autoref{sec:predictions} definierte Anforderung an das Testsystem, dass der jeweils aktuelle Status des Clusters erkannt und im Modell gespeichert werden muss.
Vorgekommen ist das auf zwei Arten, die im folgenden erläutert werden.

\subsubsection{Nicht erkannte Nodes auf Host 2}
\label{sec:notDetectedDataHost2}

Einer der beiden Fälle ist, dass ausführende Nodes von Anwendungen bzw. Attempts nicht erkannt bzw. ausgegeben wurden.
Hier geht es jedoch nicht um Anwendungen bzw. Attempts, die zwar bereits gestartet wurden, für die aber noch kein \ac{AppMstr} allokiert werden konnte.
In diesen Fällen ist es daher das normale Verhalten von Hadoop, keinen ausführenden Node anzugeben, da keiner vorhanden ist.
Wenn dieser Status zu lange anhält, wurden die Attempts bzw. \ac{AppMstr} durch Hadoop mit einem Timeout beendet.

Anders sieht das jedoch in den sechs Tests 7.1, 8 und 23 bis 26 aus.
In diesen Tests wurden zwar regulär die Daten der Nodes ermittelt und auch in den Logdateien ausgegeben, jedoch nicht alle ausführenden Nodes von Anwendungen und Attempts.
Konkret betrifft das hier alle Nodes der betroffenen \ac{AppMstr} auf Host 2, da in den betroffenen sechs Tests die Nodes erkannt und auch ausgegeben wurden, wenn sich diese auf Host 1 befunden haben, also Node 1 bis Node 4.
Während die betroffenen Nodes gemäß des SSH"=Logs fast immer von Hadoop Übertragen wurden, wurden die Nodes auf Host 2 in einigen Tests jedoch nicht gespeichert.
Zwar tritt hierbei ein gewisses Muster auf (pro Seed die jeweils zuerst ausgeführten Tests mit Nodes auf beiden Hosts), allerdings konnte dieser Fehler nicht gezielt reproduziert werden.
Bei der erneuten Ausführung der Testkonfiguration 7 (Test 7.2) wurden alle Nodes korrekt erkannt und vom Testsystem im Programmlog gespeichert.
Zum gegenwärtigen Zeitpunkt kann daher nicht gesagt werden, weshalb die ausführenden Nodes in den betroffenen Testfällen nicht immer gespeichert wurden.
Es kann nur vermutet werden, dass während dem Parsen der übertragenen Daten mit diesen Daten die betroffenen Nodes im Modell nicht gefunden werden konnten (vgl. \todo{Parser/Node-Speicherung, da erklären, dass Objekt vom Node gespeichert wird und nicht ID}).
Die Gründe dafür sind jedoch unklar.

\subsubsection{Diagnostic"=Daten von Anwendungen}
\label{sec:notDetectedDataDiagnostics}

Was bei allen Tests aufgefallen ist, dass die Diagnostic"=Daten von Anwendungen nicht im Programmlog enthalten sind.
Auch hier wurden die entsprechenden Diagnostic"=Daten von Hadoop an das Testsystem übertragen, dort jedoch nicht gespeichert im Gegensatz zu den Diagnostic"=Daten der Attempts.
Zur Auswertung der Daten im Rahmen der Evaluation ist dies zwar irrelevant, da dies auch aufgrund der Daten der Attempts geschehen kann, allerdings wird die entsprechende Anforderung an das Testsystem nicht erfüllt, wonach die Daten gespeichert werden müssen.

Eine Analyse ergab, dass die Diagnostic"=Daten der Anwendungen aufgrund eines falsch gesetzten Attributs in der \texttt{ApplicationResult}"=Klasse des Parsers nicht im Testsystem gespeichert werden konnten. \todo{Reflexion: Hätte bei vorabtests erkannt werden müssen!}
Da die Diagnostic"=Daten der Anwendungen eine Zusammenfassung der gesamten Anwendung darstellen, und alle Diagnostic"=Daten bereits durch die der Attempts vorhanden waren, wurde hier auf erneute Testausführungen verzichtet.

\subsection{Nicht erkannte, injizierte bzw. reparierte Komponentenfehler}
\label{sec:noDetectedFault}

% SuT/Test-Constraint StartNode 4 bei #17-28

\subsection{Nicht gestartete Anwendungen}
\label{sec:notStartedApps}

% Multiapp-Constraint bei #29-32

% Zu wenig Submitter bei #31/32
