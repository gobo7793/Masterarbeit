\section{Statistische Kenndaten}
\label{sec:evaluationStats}

Die Dauer aller Simulationen betrug ca. 4:16:44 Stunden, die gesamte Ausführungsdauer inkl. Starten und Beenden des Clusters bei jeder Konfiguration betrug ca. 5:19:57 Stunden.
Von den 290 Testfällen, die ausgeführt werden hätten sollen, wurden nur 222 \glspl{Testfall} (77 \%) ausgeführt.
Der Grund für den Abbruch von 14 \glspl{Test} liegt zum Großteil im in \cref{subsec:oracleImpl} beschriebenen Abbruch der Simulation, wenn keine Rekonfiguration des Clusters mehr möglich ist, also bei allen Nodes des Clusters ein Komponentenfehler injiziert und dies beim Monitoring erkannt wurde.
Ein \gls{Test} wurde aufgrund der zu geringen Anzahl an Submittern abgebrochen, was in \cref{subsec:notEnoughSubmitter} genauer erläutert wird.

Insgesamt wurde bei allen \glspl{Test} 439 Komponentenfehler aktiviert (14 \% von 3100 möglichen), von denen jedoch nicht alle injiziert wurden, da bei einigen Testfällen beide Komponentenfehler der Nodes gleichzeitig aktiviert wurden.
In diesen Fällen überwog gemäß \cref{subsec:yarnComponentFaults} die Aktivierung es Komponentenfehlers, der den Node komplett beendet.
Von allen aktivierten Komponentenfehlern wurden während der Simulationen 262 Komponentenfehler deaktiviert bzw. repariert, was eine Quote von 60 \% ergibt.
In 4 der ausgeführten Testfällen wurde jedoch kein einziger Komponentenfehler deaktiviert, weshalb die \glspl{Test} der Konfigurationen 4, 5.1, 5.2 und 6 entsprechend frühzeitig abgebrochen wurden (vgl. \cref{subsec:actDeactFaults} und \cref{subsec:noReconf36}).

Bei den 43 \glspl{Test} wurden 408 \glspl{Anwendung} im Cluster gestartet, von denen mit 204 rund die Hälfte erfolgreich und damit vollständig ausgeführt wurden, aufgrund eines Fehlers vorzeitig beendet bzw. gefailt waren mit 110 etwas mehr als ein Viertel der gestarteten Anwendungen.
Vorzeitig abgebrochen wurden bei den \glspl{Test} 52 \glspl{Anwendung} (13 \%), was 42 \glspl{Anwendung} macht, die zum Ende der Simulationen noch ausgeführt wurden.
Nicht eingerechnet sind hier 29 nicht gestartete Anwendungen, die Gründe hierfür sind in \cref{subsec:notStartedApps} erläutert.
Für die gestarteten \glspl{Anwendung} wurden 555 \glspl{Attempt} gestartet, was im Schnitt 1,36 \glspl{Attempt} pro \gls{Anwendung} ergibt.
Auffällig ist hierbei, dass mit 214 \glspl{Attempt} 9 \glspl{Attempt} mehr aufgrund eines \gls{AppMstr}"=Timeouts abgebrochen wurde, als während der Simulation erfolgreich beendet wurden (203 Attempts).
32 weitere \glspl{Attempt} wurden aufgrund eines Fehlers im Map"=Task abgebrochen, 12 weitere terminierten mit dem Exitcode -100, was ebenfalls auf Fehler hindeutet.
Das ergibt dadurch eine Quote von 46,5 \% aller gestarteten Attempts, die nicht erfolgreich abgeschlossen werden konnten.
Beim Monitoring wurden 3150 Anwendungs"=Container erkannt, was im Schnitt 7,72 \gls{Container} pro \gls{Anwendung} bzw. 5,68 pro \gls{Attempt} ergibt.
Da bei den zu startenden \glspl{Anwendung} einige kleine und einige sehr ressourcenintensive \glspl{Anwendung} enthalten sind (vgl. \cref{subsec:appSelection}), kann sich die Anzahl der \gls{Container} zwischen den einzelnen \glspl{Anwendung} sehr unterscheiden.

Vom Oracle wurden bei allen \glspl{Test} zusammengezählt 78.825 Constraints validiert, von denen 573 vom Oracle als ungültig validiert wurden (0,73 \%).
Die meisten ungültigen Constraints hatten hierbei die \glspl{Test} 31.2 und 32 mit 40 bzw. 42 Constraints (von jeweils 5140 geprüften), die höchste Quote Konfiguration 8 mit 1,97 \% der Constraints (13 von 661).
Der Hauptgrund für die teilweise sehr hohe Anzahl an ungültigen Constraints vor allem liegt darin, dass die Constraints für fehlerhaften \glspl{Anwendung} auch in nachfolgenden Testfällen innerhalb einer Ausführung einer \gls{Testkonfiguration} entsprechend erkannt werden (vgl. \cref{subsec:failedApps}).
Dies resultiert in bis zu 34 ungültigen Constraints für fehlerhafte \glspl{Anwendung} bei den einzelnen Tests.

\todo{Zusammenfassung, hier erwähnen, dass MUT schneller und weniger failapps hatte?}
