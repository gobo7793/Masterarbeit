\section{Implementierung des \glsentryshort{YARN}"=Modells}
\label{sec:yarnModel}

Das implementierte \gls{YARN}"=Modell besteht, wie bereits in \cref{sec:modelArchitecture} gezeigt, aus fünf Komponenten und den Komponentenfehlern der hier relevanten \gls{YARN}"=Komponenten.
Die vier implementierten \gls{YARN}"=Komponenten sind die Anwendungen, ihre \glspl{Attempt} und Container, sowie die Nodes.
Zudem wurde eine Klasse implementiert, die zur Repräsentation des \gls{RM} und als Controller im Rahmen des Testens mit \gls{ss} dient.
Einen Überblick über den Aufbau des implementierten \gls{YARN}"=Modells gibt folgendes Klassendiagramm:

\begin{figure}[h]
    \includegraphics{./resources/yarnModel_ls_MA.pdf}
    \caption[Grundlegender Aufbau des \glsentryshort{YARN}"=Modells]
        {Grundlegender Aufbau des \gls{YARN}"=Modells.
        Assoziationen und weitere Verbindungen zum Treiber und \glsentryshort{ss} sind hier aus Gründen der Übersichtlichkeit nicht dargestellt.}
    \label{fig:yarnModelClassDiagram}
\end{figure}

Im Klassendiagramm wird zudem ersichtlich, dass jedem Client mehrere \glspl{Anwendung} in Form der Klasse \texttt{YarnApp} zugeordnet sind, jeder \gls{Anwendung} mehrere \glspl{Attempt} (\texttt{YarnAppAttempt}) und jedem \gls{Attempt} mehrere Anwendungs"=Container (\texttt{YarnAppContainer}).
Der Client stellt somit auch die den relevanten \gls{YARN}"=Komponenten übergeordnete Komponente dar.

Zunächst wird im Folgenden die dem Modell übergeordnete zentrale Klasse \texttt{Model} erläutert, danach die relevanten \gls{YARN}"=Komponenten mit ihren Komponentenfehlern, anschließend die anderen Komponenten des \gls{YARN}"=Modells.
Der Aufbau des Benchmark"=Controllers wird in \cref{sec:benchmarkController} erläutert.

\subsection{Die Klassen Model und ModelSettings}
\label{subsec:modelClass}

Die Klasse \texttt{Model} stellt die zentrale Schnittstelle des Testsystems mit \gls{ss} dar (vgl. \cref{subsec:ssharpModel}), während die Klasse \texttt{ModelSettings} alle generellen, variablen Einstellungen und Konstanten des \gls{YARN}"=Modells bereitstellt.
Da die \texttt{Model}"=Klasse auch das gesamte Modell repräsentiert, wird sie zur Verwaltung des von \gls{ss} auszuführenden Modells genutzt.
Hierfür werden alle Komponenten wie Clients oder \glspl{Anwendung} zusätzlich zur Struktur innerhalb des Modells auch in \texttt{Model} gespeichert, welche zur Interaktion mit \gls{ss} entsprechenden Attributen versehen sind (vgl. \cref{subsec:ssharpModel}).

Daneben dient die Klasse auch zur Initialisierung des gesamten Modells.
Hierbei werden zunächst der Controller, der Treiber in Form der benötigten Parser und Connectoren, sowie die Nodes des Clusters initialisiert.
Anschließend wird für jeden Client eine gewisse Anzahl an \texttt{YarnApp}"=Instanzen zum Speichern der Daten von Anwendungen, für jede \gls{Anwendung} eine gewisse Anzahl an \texttt{YarnAppAttempt}"=Instanzen für Attempts, sowie für jeden \gls{Attempt} eine gewisse Anzahl an \texttt{YarnAppContainer} für die Daten der Anwendungs"=Container initialisiert.
Die genaue Anzahl der erzeugten Instanzen kann hierbei für jede \gls{YARN}"=Komponente und auch für Clients nach Bedarf angepasst werden, wodurch auch einzelne Komponenten wie \zB in der Fallstudie die Anwendungs"=Container, deaktiviert werden können.

Alle initialisierten \gls{YARN}"=Komponenten werden durch die \texttt{Model}"=Klasse auch innerhalb des Modells zur Verfügung gestellt, sofern Komponenten diese benötigen.
Darunter zählen auch die bei der Ausführung des Modells benötigten Parser und Connectoren des Treibers.
Aufgrund der Einschränkungen von \gls{ss} im Umgang mit dem Treiber (vgl. \cref{subsec:driverModelIntegration}), sowie zur einfacheren Bereitstellung von benötigten Komponenten und Funktionen im Modell, ist die \texttt{Model}"=Klasse als Singleton realisiert.

Die \texttt{ModelSettings}"=Klasse dient zum Speichern der variablen Einstellungen sowie zum Bereitstellen von generellen, Modell- oder Testsystemweiten Konstanten.
Gespeichert und bereitgestellt werden hier Daten wie \zB die Zugangsdaten der SSH"=Verbindungen oder der genutzte \texttt{HostMode} (vgl.  \cref{subsec:implementedConnectors,subsec:hostMode}).
Die \texttt{ModelSettings}"=Klasse ist dabei zur Verwaltung des \texttt{HostMode}s zuständig und dafür verantwortlich, die vom \texttt{HostMode} abhängigen Pfade und Adressen dem Treiber bereit zu stellen.
Dies betrifft \zB den Pfad zum benötigten Setupscript (vgl. \cref{subsec:scripts}) oder die zur Nutzung der \gls{REST}"=API benötigten Adressen.
Eine Besonderheit bildet hierbei die Eigenschaft \texttt{HttpUrl} der \texttt{YarnNode}s, welche beim Initialisieren des Modells durch die \texttt{ModelSettings} die zum \texttt{HostMode} passende Adresse erhält (vgl. \cref{subsec:yarnComponents,subsec:hostMode}).

\subsection{Relevante \glsentryshort{YARN}"=Komponenten}
\label{subsec:yarnComponents}

Die vier implementierten, relevanten \gls{YARN}"=Komponenten sind die Anwendungen, ihre \glspl{Attempt} und \gls{Container} sowie die Nodes des Clusters.
Diese vier implementierten \gls{YARN}"=Komponenten stellen das zum Testen mit \gls{ss} benötigte Modell des \gls{SuT} dar (vgl. \cref{subsec:ssharpModel}).
Obwohl die die Anwendungs"=Container in dieser Fallstudie nicht benötigt werden, waren sie für die Fallstudie \cite{Eberhardinger2018} notwendig, welche ebenfalls mit dem hier beschriebenen Modell durchgeführt wurde.

Eine Übersicht über die Implementierung der \gls{YARN}"=Komponenten gibt folgendes Klassendiagramm:

\begin{figure}[h]
    \includegraphics[width=\columnwidth]{./resources/yarnComponents.pdf}
    \caption[Für die Fallstudie relevante, implementierte \glsentryshort{YARN}"=Komponenten]
        {Für die Fallstudie relevante, implementierte \glsentryshort{YARN}"=Komponenten, hier dargestellt mit den wichtigsten Eigenschaften und Methoden.
        Dies sind alle für die spätere Durchführung und zur Ausgabe des Zustandes (vgl. \cref{subsec:dataOrganisation}) wichtigen Eigenschaften und Methoden.
        Aus Gründen der Übersichtlichkeit sind die implementierten Komponentenfehler, einige der \texttt{IYarnReadable} bereitgestellten, relevanten Eigenschaften und Methoden, sowie die Klasse \texttt{YarnAppContainer} nicht aufgeführt.}
    \label{fig:yarnComponentsClassDiagram}
\end{figure}

Die Eigenschaft \texttt{AmHost} speichert den ausführenden Node des \gls{AppMstr} der \gls{Anwendung} bzw. des Attempts, die Eigenschaft \texttt{IsKillable} gibt an, ob eine \gls{Anwendung} derzeit ausgeführt wird und somit vorzeitig abgebrochen werden kann.
Die Eigenschaften \texttt{Diagnostics} bzw. \texttt{HealthReport} stellen von Hadoop zur Verfügung gestellte, weitere Diagnostik"=Informationen bei Fehlern dar.
Die \texttt{State}"=Eigenschaften bzw. \texttt{FinalState} speichern die von Hadoop angegebenen Zustände der \gls{YARN}"=Komponenten.
Hierfür wurden entsprechende Auflistungen basierend auf den in \cite{HadoopRmApi271} angegebenen möglichen Werten für die jeweiligen Zustände im Modell implementiert.

Da für diese Fallstudie die Daten der \gls{Container} selbst nicht relevant sind, wird im hier verwendeten Modell nur gespeichert, wie viele Anwendungs"=Container beim Monitoring im aktuellen \gls{Testfall} (\texttt{RunningContainerCount}) bzw. für alle bisher ausgeführten \glspl{Testfall} kumuliert (\texttt{DetectedContainerCount}) erkannt wurden.
Für die Tests \cite{Eberhardinger2018} werden die Daten der \gls{Container} genauso wie die der anderen \gls{YARN}"=Komponenten gespeichert.
Hierfür enthalten die Klassen \texttt{YarnAppAttempt} und \texttt{YarnAppContainer} entsprechende Eigenschaften zur jeweiligen Zuordnung, analog zu denen zwischen \texttt{YarnApp} und \texttt{YarnAppAttempt}.
Analoge Zuordnungen bestehen auch zu den Clients bzw. den Anwendungs"=Containern, sofern benötigt.
Die Eigenschaft \texttt{AmContainerId} speichert zudem die Container"=ID des \gls{AppMstr}"=Containers.

Die Eigenschaften mit dem Präfix \texttt{CPU} bzw. \texttt{Memory} in \texttt{YarnNode} dienen zur Speicherung der derzeitigen Auslastung der CPU"=Kerne bzw. des Speichers eines Nodes.
Benötigt werden diese Werte zur Berechnung, ob ein Komponentenfehler aktiviert oder deaktiviert wird.
Die durch die Basisklasse \texttt{YarnHost} bereitgestellte Eigenschaft \texttt{HttpUrl} beschreibt die für die Nutzung der \gls{REST}"=API benötigte Adresse des Nodes (vgl. \cref{subsubsec:implRestConnector}).
Da die Adresse vom \texttt{HostMode} abhängig ist, wird sie mithilfe der \texttt{ModelSettings} beim initialisieren des Modells entsprechend festgelegt (vgl. \cref{subsec:hostMode,subsec:modelClass}).

Die Eigenschaften \texttt{SutConstraints} und \texttt{TestConstraints} sowie die Methoden \texttt{MonitorStatus()} und \texttt{SetStatus()} werden von \texttt{IYarnReadable} bereitgestellt und speichern die Constraints bzw. dienen zur Durchführung des Monitorings der implementierten Komponenten (vgl. \cref{subsec:yarnComponentInterface}).
Die Start"= und Stop"=Methoden sowie die Eigenschaften \texttt{IsActive} und \texttt{IsConnected} in \texttt{YarnNode} dienen zur Identifikation und Injizierung bzw. Reparieren der Komponentenfehlern (vgl. \cref{subsec:yarnComponentFaults})

Neben den dargestellten, relevanten Eigenschaften und Methoden wurden zahlreiche weitere implementiert, welche einerseits zur Vollständigkeit der implementierten Komponenten für die Tests \cite{Eberhardinger2018}, andererseits auch zur Ausführung mithilfe des \gls{ss}"=Frameworks benötigt werden.
Letztere sind \zB zur Speicherung von Strings notwendig, welche aufgrund der Einschränkungen von \gls{ss} (vgl. \cref{sec:ssharp}) \uU nicht jederzeit frei genutzt werden können.
Strings sind im \gls{YARN}"=Modell daher zur Speicherung immer als  \texttt{char}"=Arrays implementiert, werden jedoch zur einfacheren Nutzung im Modell in Strings konvertiert:

\begin{lstlisting}[label=lst:modelCharArrayAsString,style=cs,
caption={[Implementierung der Eigenschaft AppId]
    Implementierung der Eigenschaft \texttt{AppId}.
    Die beiden Methoden \texttt{GetCharArrayAsString} und \texttt{SetCharArrayOnString} führen die Konvertierung in den \texttt{char}"=Array bzw. des \texttt{char}"=Arrays in einen String durch.
    Das Attribut \texttt{NonSerializable} definiert, dass die Eigenschaft bei der Ausführung der Simulation von \gls{ss} ignoriert wird.}]
public char[] AppIdActual { get; }

[NonSerializable]
public string AppId
{
  get { return ModelUtilities.GetCharArrayAsString(AppIdActual); }
  set { ModelUtilities.SetCharArrayOnString(AppIdActual, value); }
}
\end{lstlisting}

Die \texttt{Update()}"=Methoden starten bei allen vier implementierten \gls{YARN}"=Komponenten die jeweiligen Monitoring"=Funktionen, bei \texttt{YarnNode} werden zudem \texttt{StartNode()} und \texttt{StartConnection()} ausgeführt um mögliche zuvor injizierte Komponentenfehler im realen Cluster zu reparieren.

Da bei der Ausführung des Modells durch \gls{ss} keine neuen Instanzen erzeugt werden können (vgl. \cref{sec:ssharp}), dienen die jeweiligen IDs der Komponenten auch als Indikator, ob die jeweilige Komponenten"=Instanz derzeit benötigt wird und somit Daten gespeichert werden sollen.
Daher wird das Monitoring auch nur dann ausgeführt, wenn der Instanz eine nicht leere ID \zB in Form der \texttt{AppId} zugewiesen wurde.

\subsection{Implementierung der Komponentenfehler}
\label{subsec:yarnComponentFaults}

Die im \gls{YARN}"=Modell implementierten Komponentenfehler wurden direkt in den entsprechenden \gls{YARN}"=Komponenten implementiert.
Implementiert wurden hierbei mit \texttt{NodeDeadFault} und \texttt{NodeConnectionErrorFault} zwei jeweils als \texttt{TransientFault} definierte Komponentenfehler für die durch \texttt{YarnNode} repräsentierten Nodes.
Während durch \texttt{NodeDeadFault} der komplette Node beendet wird, trennt \texttt{NodeConnectionErrorFault} nur die Verbindung des Nodes zum Cluster.
Die dazugehörigen Effekt"=Klassen der Komponentenfehler sind jeweils als innere Klassen in \texttt{YarnNode} implementiert.

Die Injizierung und das Reparieren der beiden Fehler geschieht mithilfe der vier Stop- bzw. Start"=Methoden wie \zB \texttt{StopNode()}, die bereits im Klassendiagramm in \cref{fig:yarnComponentsClassDiagram} zu sehen sind.
Wenn ein Komponentenfehler durch das Framework aktiviert wird, wird durch die Effekt"=Klasse die jeweilige Stop"=Methode aufgerufen und so der Fehler injiziert:

\begin{lstlisting}[label=lst:faultInjection,,style=cs,
caption={[Injizierung des Komponentenfehlers NodeDeadFault]
    Injizierung des Komponentenfehlers \texttt{NodeDeadFault} (gekürzt).
    Sollte der Node nicht beendet werden, wird die Injizierung einmalig erneut versucht.
    \texttt{CmdConnector.Faulting} stellt die zur Injizierung verwendete SSH"=Verbindung dar.}]
public class YarnNode : YarnHost, IYarnReadable
{
  [NodeFault]
  public readonly Fault NodeDeadFault = new TransientFault();
  public IHadoopConnector FaultConnector { get; set; }
  
  public bool StopNode(bool retry = true)
  {
    if(IsActive)
    {
      var isStopped = FaultConnector.StopNode(Name);
      if(isStopped)
        IsActive = false;
      else if(retry)
        StopNode(false); // t§§ry again once
    }
    return !IsActive;
  }
  
  [FaultEffect(Fault = nameof(NodeDeadFault))]
  public class NodeDeadEffect : YarnNode
  {
    public override void Update()
    {
      StopNode();
    }
  }
}

public class CmdConnector : IHadoopConnector
{
  private SshConnection Faulting { get; }
  
  public bool StopNode(string nodeName)
  {
    var id = DriverUtilities.ParseInt(nodeName);
    Faulting.Run($"{Model.HadoopSetupScript} hadoop stop {id}", IsConsoleOut);
    return !CheckNodeRunning(id);
  }
}
\end{lstlisting}

Das Reparieren von Komponentenfehlern geschieht analog hierzu.
Hierfür werden in der \texttt{Update()}"=Methode die beiden Start"=Methoden aufgerufen, die einen Fehlerhaften Node reparieren.
Eine Besonderheit bildet hierbei die Reparatur des Komponentenfehlers \texttt{NodeConnectionErrorFault}, bei der der Node komplett neu gestartet wird, da es sonst passieren kann, dass der wieder ans Netzwerk angebundene Node sich nicht mit dem \gls{RM} verbindet.

Da beide Fehler zudem auch gleichzeitig aktiviert werden können, wurde dem Komponentenfehler \texttt{NodeDeadFault} mithilfe entsprechender \gls{ss}"=Funktionen eine höhere Priorität vergeben, wodurch dieser Vorrang vor dem anderen Komponentenfehler erhält.
Dadurch wird in solchen Fällen der Node beendet und nicht zunächst noch zusätzlich auch vom Netzwerk getrennt.

Zur einfachen Identifikation der aktiven Komponentenfehler innerhalb des \gls{YARN}"=Modells dienen die beiden Eigenschaften \texttt{IsActive} und \texttt{IsConnected}.
In \cref{lst:faultInjection} wird bereits die Auswirkung der beiden Eigenschaften gezeigt, indem verhindert wird, dass ein möglicherweise bereits injizierter bzw. reparierter Komponentenfehler erneut injiziert bzw. repariert wird.
Sie dienen aber auch zur Validierung der Constraints, bei denen mithilfe der beiden Eigenschaften geprüft wird, ob ein Node korrekt als aktiv bzw. defekt erkannt wurde.

\subsection{Aktivierung von Komponentenfehler}
\label{subsec:faultActivation}

Ob ein Komponentenfehler in einem \gls{Testfall} aktiviert wird, ist abhängig von folgenden Parametern:

\begin{itemize}
    \item Auslastung des Nodes im vorhergehenden Testfall
    \item Generelle Wahrscheinlichkeit zur Fehleraktivierung
    \item Einer Zufallszahl
\end{itemize}

Der hierfür benötigte Zufallsgenerator wird mithilfe des in \cref{subsec:testcaseGeneration} spezifizierten Basisseeds initialisiert.
Da der Zufallsgenerator ein statischer Generator ist, werden über einen \gls{Test} bei der gleichen Anzahl an möglichen Komponentenfehler immer die gleichen Werte zurückgegeben, nicht jedoch zwingend für einen bestimmten Komponentenfehler eines Nodes.
Die Komponentenfehler werden damit nicht automatisiert durch \gls{ss} aktiviert (vgl. \cref{subsec:ssharpExecution}), sondern werden mithilfe von speziell hierfür entwickelten Klassen und Methoden aktiviert und im realen Cluster injiziert.

Um zu bestimmen, ob ein Komponentenfehler aktiviert wird, sind alle Komponentenfehler mit dem Attribut \texttt{NodeFault} markiert.
Mithilfe dieses Attributes wird bei der Ausführung eines Testfalls folgendermaßen berechnet, ob der Komponentenfehler aktiviert wird:

\begin{lstlisting}[label=lst:faultActivationCalc,style=cs,
caption={[Berechnung der Aktivierung von Komponentenfehlern]
    Berechnung der Aktivierung von Komponentenfehlern (zusammengefasst).}]
var node = AllNodes.First(n => n.Name == nodeName);
var nodeUsage = (node.MemoryUsage + node.CpuUsage) / 2;

if(nodeUsage < 0.1) nodeUsage = 0.1;
else if(nodeUsage > 0.9) nodeUsage = 0.9;

NodeUsageOnActivation = nodeUsage; // f§§or u§§sing on repairing

var faultUsage = nodeUsage * ActivationProbability * 2;

var probability = 1 - faultUsage;
var randomValue = RandomGen.NextDouble();
Logger.Info($"Activation probability: {probability} < {randomValue}");
return probability < randomValue;
\end{lstlisting}

Die Entscheidung zur Deaktivierung eines Komponentenfehlers verhält sich analog.
Anstatt der generellen Aktivierungswahrscheinlichkeit wird hierbei die generelle Wahrscheinlichkeit zur Deaktivierung der Komponentenfehler genutzt.
Außerdem spielt bei der Deaktivierung die Auslastung des Nodes zum Zeitpunkt der Aktivierung eine Rolle, welche hierzu in der Eigenschaft \texttt{NodeUsageOnActivation} des Attributs entsprechend gespeichert und zur Deaktivierung genutzt wird.

\subsection{Interface IYarnReadable und Monitoring}
\label{subsec:yarnComponentInterface}

Das Interface \texttt{IYarnReadable} ist das zentrale Erkennungsmerkmal der im Modell abgebildeten und implementierten \gls{YARN}"=Komponenten.
Es dient zum einen zur Identifikation aller implementierten \gls{YARN}"=Komponenten, andererseits stellt es auch Eigenschaften und Methoden bereit, welche einerseits dem Testen in \gls{ss} dienen, primär aber dem Ermitteln der Daten aus dem realen Cluster:

\begin{itemize}
    \item \texttt{GetId()}
    \item \texttt{StatusAsString()}
    
    \item \texttt{Parser}
    \item \texttt{IsSelfMonitoring}
    \item \texttt{MonitorStatus()}
    \item \texttt{SetStatus()}
    
    \item \texttt{PreviousParsedComponent}
    \item \texttt{CurrentParsedComponent}
    \item \texttt{SutConstraints}
    \item \texttt{TestConstraints}
\end{itemize}

Die beiden erstgenannten Methoden dienen primär zu Debugging"=Zwecken und zur Rückgabe der ID beim Zugriff auf die jeweiligen Komponenten mithilfe das Interfaces bzw. der Werte aller Eigenschaften der Komponente als ein String.

Die nachfolgenden vier Eigenschaften und Methoden dienen zum Monitoring der entsprechenden \gls{YARN}"=Komponenten.
Während die Eigenschaft \texttt{Parser} den zu verwendenden Parser (vgl. \cref{subsec:implementedParsers}) speichert, dient die Eigenschaft \texttt{IsSelfMonito""ring} zur Unterscheidung, ob die Daten einer Komponente von dieser selbst ermittelt werden oder dies die übergeordnete Komponente durchführt.
Diese Unterscheidung ist nötig, da \gls{YARN} hierfür zwei unterschiedliche Schnittstellen bietet: die Rückgabe der Daten durch die \gls{CLI} oder mithilfe der \gls{REST}"=API.
Ausführlichere Informationen in diesem Kontext sind in \cref{sec:sshDriver} zu finden.
Bei der Nutzung der \gls{CLI} zur Ermittlung der Daten eignet sich daher die Selbstermittlung der Daten besser, während bei der Nutzung der REST"=API die Ermittlung der Daten durch die übergeordnete Komponente geeigneter ist.
Aus diesem Grund ist auch die Methode \texttt{SetStatus()} definiert, da hier unabhängig von der Datenermittlung der aktuelle Status der Komponente abgespeichert werden kann.
Die Durchführung des Monitoring findet in beiden Fällen jedoch mithilfe der Methode \texttt{MonitorStatus()} statt:

\begin{lstlisting}[label=lst:monitorAppStatus,style=cs,
caption={[Implementierung der Methode MonitorStatus() in der Klasse YarnApp]
    Implementierung der Methode \texttt{MonitorStatus()} in der Klasse \texttt{YarnApp} (gekürzt).
    Das Monitoring der anderen Komponenten erfolgt analog hierzu.}]
public void MonitorStatus()
{
  if(IsSelfMonitoring)
  {
    var parsed = Parser.ParseAppDetails(AppId);
    if(parsed != null)
    SetStatus(parsed);
  }
  
  var parsedAttempts = Parser.ParseAppAttemptList(AppId);
  foreach(var parsed in parsedAttempts)
  {
    // search attempt with t§§his id or an free attempt
    attempt.IsSelfMonitoring = IsSelfMonitoring;
    if(IsSelfMonitoring)
      attempt.AttemptId = parsed.AttemptId;
    else
    {
      attempt.SetStatus(parsed);
      attempt.MonitorStatus();
    }
  }
}
\end{lstlisting}

Beim Monitoring der untergeordneten Komponenten wird zunächst immer geprüft, ob bereits eine Instanz mit der ID der Komponente vorhanden ist.
Wenn dies der Fall ist, werden die vom realen Cluster ermittelten Daten weiterhin in der bereits bestehenden Instanz gespeichert, ansonsten wird eine leere Instanz genutzt um die Daten der Subkomponente zu speichern.
Wenn keine freie Instanz mehr nötig ist, wird eine entsprechende \texttt{OutOfMemoryException} ausgelöst, damit die Ausführung des Modells abgebrochen werden kann.

Eine Besonderheit bildet das Monitoring der Anwendungs"=Container.
Da eine \gls{Anwendung} sehr schnell eine sehr hohe Anzahl an \gls{Container} allokiert und jede Container"=Instanz im Modell Speicherplatz benötigt, werden nur die Daten der während des Monitoring ausgeführten \gls{Container} ermittelt.
Bei \glspl{Anwendung} und \glspl{Attempt} werden dagegen auch die Daten von bereits beendeten \glspl{Anwendung} bzw. \glspl{Attempt} gespeichert.

Die vier restlichen Eigenschaften und Methoden des Interfaces dienen zur Auswertung der Komponente durch \gls{ss}.
Die beiden Eigenschaften \texttt{SutConstraints} und \texttt{TestConstraints} dienen zur Implementierung der in \cref{sec:requirements} definierten Anforderungen in Form von Constraints.

\subsection{Constraints der \glsentryshort{YARN}"=Komponenten}
\label{subsec:yarnComponentConstraints}

Einige der in \cref{sec:requirements} definierten Anforderungen an das \gls{SuT} und gesamte Testsystem sind auch für die \gls{YARN}"=Komponenten relevant und werden in Form von Constraints im Modell implementiert (vgl. \cref{subsec:ssharpModel,sec:clusterSetup,sec:requirements}).
Die relevanten Bestandteile der Anforderungen für die jeweiligen Komponenten sind mithilfe der beiden in \texttt{IYarnReadable} definierten Eigenschaften \texttt{SutConstraints} und \texttt{TestConstraints} implementiert.
Realisiert sind die beiden Eigenschaften für die Constraints jeweils als \texttt{Func<bool>[]}:

\begin{lstlisting}[label=lst:constraintDefinition,style=cs,
caption={[Definition der Constraints in YarnApp]
    Definition der Constraints in \texttt{YarnApp} (gekürzt)}]
public Func<bool>[] SutConstraints => new Func<bool>[]
{
  // task will be completed i§§f not canceled
  () =>
  {
    if(FinalStatus != EFinalStatus.FAILED)
      return true;
    if(!String.IsNullOrWhiteSpace(Name) &&
        Name.ToLower().Contains("fail job"))
      return true;
    return false;
  },
  // configuration will be updated
};

public Func<bool>[] TestConstraints => new Func<bool>[]
{
  // current state i§§s detected and saved
  () =>
  {
    var prev = PreviousParsedComponent as IApplicationResult;
    var curr = CurrentParsedComponent as IApplicationResult;
    // compare prev, curr and t§§his and r§§eturn the result
    // or otherwise
    return false;
  },
};
\end{lstlisting}

Die Constraints werden im Anschluss an das Monitoring vom Oracle validiert (vgl. \cref{subsec:oracleImpl}).
Die Constraints sind so definiert, dass im Falle einer erfolgreichen Validierung \texttt{true} zurückgegeben wird, in allen anderen Fällen die Rückgabe \texttt{false} dagegen eine nicht erfolgreiche Validierung anzeigt.

Wenn die ID der Komponenten"=Instanzen leer ist, und die jeweilige Instanz somit derzeit nicht im Modell zum Speichern der Daten des realen Clusters benötigt wird, werden die Constraints immer erfolgreich validiert.

\subsection{Implementierung des Clients}
\label{subsec:yarnClient}

Der Client im \gls{YARN}"=Modell simuliert einen Client und dient somit zum Starten der Benchmarks.
Die Auswahl des zu startenden Benchmarks erfolgt durch den Benchmark"=Controller, welcher in \cref{sec:benchmarkController} erläutert wird.
Jeder Client besitzt hierzu einen eigenen Benchmark"=Controller, womit die auszuführenden Benchmarks für jeden Client unabhängig von anderen Clients ausgewählt werden.
Ein Client kann jedoch nur eine \gls{Anwendung} gleichzeitig starten und muss eine zuvor gestartete \gls{Anwendung} beenden, bevor er eine neue starten kann.
Dies wird jedoch nur durchgeführt, wenn sich der auszuführende Benchmark geändert hat:

\begin{lstlisting}[label=lst:startClientBenchmark,style=cs,
caption={[Auswahl und Start des nachfolgenden Benchmarks]
    Auswahl und Start des nachfolgenden Benchmarks (gekürzt).
    Die Methode \texttt{ChangeBenchmark()} des Benchmark"=Controllers wird in \cref{subsec:selectionNextBenchmark} erläutert.}]
public void UpdateBenchmark()
{
  var benchChanged = BenchController.ChangeBenchmark();
  
  if(benchChanged)
  {
    StopCurrentBenchmark();
    StartBenchmark(BenchController.CurrentBenchmark);
  }
}

public void StartBenchmark(Benchmark benchmark)
{
  if(benchmark.HasOutputDir)
    SubmittingConnector.RemoveHdfsDir(benchmark.GetOutputDir(ClientDir));
  var appId = SubmittingConnector.StartApplicationAsyncTillId(benchmark.GetStartCmd(ClientDir));
  // save application id
}
\end{lstlisting}

Da die auf dem Cluster ausgeführten \glspl{Anwendung} \uU nicht gestartet werden, wenn im \gls{HDFS} das Ausgabeverzeichnis bereits vorhanden ist, muss dieses beim Starten eines Benchmarks zunächst gelöscht werden.
Um mehrere Clients unabhängig voneinander nutzen zu können, besitzt jeder Client zudem ein spezifisches Verzeichnis, das seiner eigenen Client"=ID entspricht.
Die Ein- und Ausgabedaten werden dadurch nur im Verzeichnis des jeweiligen Clients gespeichert.

Wenn eine \gls{Anwendung} gestartet wurde, wird diese zunächst synchron ausgeführt, bis von der gestarteten \gls{Anwendung} ihre vom Cluster zugewiesene Anwendungs"=ID zurückgegeben wird.
Diese ID wird vom Client abgespeichert und wird dafür benötigt, um in späteren Testfällen die \gls{Anwendung} wieder beenden zu können
Zudem wird auch eine noch leere \texttt{YarnApp}"=Instanz ermittelt und dieser die ID ebenfalls zugewiesen, um diese analog zu den anderen \gls{YARN}"=Komponenten zum Speichern der Daten der \gls{Anwendung} zu nutzen.
Der Unterschied hierbei ist jedoch, dass immer eine neue Instanz genutzt wird, da eine neue \gls{Anwendung} automatisch immer eine ID erhält, welche im Cluster noch nicht existiert.
Wenn keine leere \texttt{YarnApp}"=Instanz mehr verfügbar ist, wird analog zum Monitoring ebenfalls eine \texttt{OutOfMemoryException} ausgelöst.

\subsection{Implementierung des Controllers}
\label{subsec:yarnController}

Der Controller repräsentiert zum einen den \gls{RM} des Hadoop"=Clusters, weshalb er auch von \texttt{YarnHost} erbt, genauso wie die Klasse der Nodes des \gls{YARN}"=Modells.
Seine Hauptaufgabe besteht jedoch darin, als Controller zum Testen mit \gls{ss} zu dienen (vgl. \cref{subsec:ssharpModel}).

Der Controller steuert einen Großteil der Ausführung eines einzelnen Testfalls und ist die einzige Komponente des \gls{YARN}"=Modells, welche direkt mit dem Oracle interagiert:

\begin{lstlisting}[label=lst:controllerUpdate,style=cs,
caption={[Update()"=Methode des Controllers]
    \texttt{Update()}"=Methode des Controllers (gekürzt).
    Eine ausführliche Beschreibung des Ablaufs der Ausführung eines Testfalls findet sich in \cref{subsec:simulationStep}.}]
public override void Update()
{
  MonitorMarp();
  
  foreach(var client in ConnectedClients)
    client.UpdateBenchmark();
  
  // optional, to allocate at least the AM container
  ModelUtilities.Sleep(5);
  
  MonitorAll();
  
  Oracle.ValidateConstraints(EConstraintType.Sut);
  Oracle.IsReconfPossible();
  Oracle.ValidateConstraints(EConstraintType.Test);
}
\end{lstlisting}

Nach einem ersten Monitoring des \gls{MARP}"=Wertes wird durch den Controller sichergestellt, dass jeder simulierte Client eine \gls{Anwendung} startet, sofern vom Benchmark"=Controller hierbei eine neue \gls{Anwendung} ausgewählt wird (vgl. \cref{subsec:yarnClient,sec:benchmarkController}).

Vor dem Monitoring wird zunächst fünf Sekunden gewartet, damit die gestarteten \glspl{Anwendung} auf dem Cluster die benötigten Ressourcen erhalten können, wodurch die Auslastung des Clusters besser ermittelt werden kann.
Zum Monitoring nutzt der Controller die von \texttt{IYarnReadable} bereitgestellte Eigenschaft um das Selbstmonitoring der einzelnen \gls{YARN}"=Komponenten zu deaktivieren und führt dabei das Monitoring der Nodes und \glspl{Anwendung} aus.
Er startet zudem bei jeder \gls{Anwendung} auch das Monitoring der jeweiligen \glspl{Attempt} bzw. dadurch auch das der Anwendungs"=Container, sofern benötigt.
Dabei wird der \gls{MARP}"=Wert hier erneut ausgelesen, da er sich abhängig von den ausgeführten \glspl{Anwendung} jederzeit verändern kann.
Abschließend startet der Controller die Validierung der Constraints durch das Oracle sowie die Prüfung, ob eine weitere Rekonfiguration des Clusters möglich ist.

Für den Controller selbst sind ebenfalls einige der in \cref{sec:requirements} definierten Anforderungen relevant.
Die hierbei relevanten Anforderungen sind ebenfalls direkt im Controller implementiert und werden durch das Oracle validiert.

\subsection{Implementierung des Oracles}
\label{subsec:oracleImpl}

Das Oracle dient zur automatisierten Validierung der in \cref{sec:requirements} definierten Anforderungen durch das Testsystem (vgl. \cref{subsec:ssharpModel}).
Hierzu werden die Constraints aller \gls{YARN}"=Komponenten und des Controllers validiert, jeweils getrennt nach Constraints für das \gls{SuT} und das gesamte Testsystem, und geprüft, ob eine Rekonfiguration des Clusters möglich ist.
Da die beiden von \texttt{IYarnReadable} bereitgestellten Eigenschaften zum Speichern der Constraints vom Typ \texttt{Func<bool>[]} sind, können so jeweils alle implementierten Constraints nacheinander validiert werden:

\begin{lstlisting}[label=lst:oracleValidateConstraints,style=cs,
caption={[Validieren der Constraints durch das Oracle]
    Validieren der Constraints durch das Oracle.
    Die zu validierenden Constraints werden im Parameter \texttt{constraints} übergeben, der Parameter \texttt{constraintType} dient zu statistischen Zwecken in \texttt{CountCheck()}.}]
public static bool ValidateConstraints(string componentId,
   Func<bool>[] constraints, EConstraintType constraintType)
{
  var isCompontenValid = true;
  for(var i = 0; i < constraints.Length; i++)
  {
    var constraint = constraints[i];
    bool isValid;
    try
    {
      isValid = constraint();
    }
    catch
    {
      isValid = false;
    }
    
    CountCheck(constraintType, isValid);
    if(!isValid)
    {
      Logger.Error($"YARN component not valid: " +
         "Constraint {i} in {componentId}");
      if(isCompontenValid)
        isCompontenValid = false;
    }
  }
  
  return isCompontenValid;
}
\end{lstlisting}

Bei der Prüfung, ob eine weitere Rekonfiguration möglich ist, wird geprüft, ob alle Nodes im Cluster defekt sind bzw. dies beim Monitoring des realen Clusters erkannt wurde.
Wenn dies der Fall ist, wird die weitere Testausführung gemäß \cref{subsec:testRequirements} abgebrochen, indem eine \texttt{Exception} ausgelöst wird:

\begin{lstlisting}[label=lst:oracleIsReconfPossible,style=cs,
caption={Prüfung nach der Möglichkeit weiterer Rekonfigurationen}]
public bool IsReconfPossible()
{
  var isReconfPossible = ConnectedNodes
     .Any(n => n.State == ENodeState.RUNNING);
  if(!isReconfPossible)
  {
    Logger.Error("No reconfiguration possible!");
    throw new Exception("No reconfiguration possible!");
  }
  return true;
}
\end{lstlisting}

Die bereits in \cref{lst:oracleValidateConstraints} gezeigte Methode \texttt{CountCheck()} dient zu statistischen Zwecken.
Hierbei wird getrennt nach Constraint"=Typ (der funktionalen Anforderungen an das \gls{SuT} oder aller Anforderungen an das Testsystem) gezählt, wie viele Constraints insgesamt validiert, und wie viele davon verletzt wurden.
Die jeweiligen Werte können beim Abschluss einer Testausführung entsprechend ausgegeben werden.
