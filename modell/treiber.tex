\section{Entwicklung des Treibers}
\label{sec:sshDriver}
\todo{Multihost-Mode irgendwo erklären}

In \cref{sec:modelArchitecture} wurde bereits aufgezeigt, dass der Treiber zur Verbindung des \ac{YARN}"=Modells mit dem realen Cluster aus den drei Komponenten Parser, Connector und der SSH"=Verbindung selbst besteht.
Der Treiber ist im \ac{YARN}"=Modell mithilfe verschiedener Interfaces zur Nutzung des Parsers und Connectors eingebunden.
Da \ac{YARN} mithilfe von Befehlen für die CLI und einer REST"=API zwei unterschiedliche Schnittstellen zum Auslesen der Daten der \ac{YARN}"=Komponenten für das Monitoring bereitstellt, wurden jeweils zwei entsprechende Parser und Connectoren hierfür entwickelt.
Andere Befehle wie \zB \ac{HDFS}"=Befehle können ebenfalls mithilfe des entwickelten CLI"=Connectors ausgeführt werden, da Connectoren mithilfe von SSH"=Verbindungen mit den Cluster"=Hosts verbunden sind.

\subsection{Grundlegender Aufbau und Integration im \acs{YARN}"=Modell}
\label{subsec:driverModelIntegration}

Zur Integration des Treibers im \ac{YARN}"=Modell stellt dieser mehrere Interfaces bereit.
Dadurch sind einerseits der Treiber und das YARN"=Modell strikt getrennt, andererseits wird es dadurch auch ermöglicht, in Zukunft andere Möglichkeiten als die hier Entwickelten zur Interaktion mit dem realen Cluster zu entwickeln und zu nutzen.

Zur Interaktion des YARN"=Modells mit dem Treiber werden dem Modell folgende Interfaces zur Verfügung gestellt:

\begin{itemize}
    \item \texttt{IHadoopParser} für Parser
    \item \texttt{IHadoopConnector} für Connectoren
    \item Von \texttt{IParsedComponent} abgeleitete Interfaces für geparste YARN"=Komponenten:
    \begin{itemize}
        \item \texttt{IApplicationResult} für Anwendungen
        \item \texttt{IAppAttemptResult} für Attempts
        \item \texttt{IContainerResult} für Anwendungs"=Container
        \item \texttt{INodeResult} für Nodes
    \end{itemize}
\end{itemize}

Das Monitoring der Daten des realen Clusters wird mithilfe des Parsers durchgeführt.
Das Interface \texttt{IHadoopParser} stellt hierfür entsprechende Parsing"=Methoden für die vier implementierten YARN"=Komponenten sowie der Übersichtslisten aller einer YARN"=Komponente untergeordneten Subkomponenten.
Zudem stellt das Parser"=Interface eine Methode zum Auslesen des aktuellen \ac{MARP}"=Wertes des Schedulers bereit.
Beim Monitoring werden immer die entsprechenden von \texttt{IParsedComponent} abgeleiteten Interfaces zur Rückgabe der ermittelten Daten genutzt.
Hierfür stellen diese Interfaces entsprechende Eigenschaften bereit, um alle mithilfe der CLI oder der REST"=API auslesbaren Daten an das YARN"=Modell übergeben zu können.

Das Connector"=Interface \texttt{IHadoopConnector} stellt alle zum Abrufen der Daten oder weiteren Interaktion wie das Injizieren von Komponentenfehlern oder Starten von Anwendungen benötigten Methoden und Befehle bereit.
Hierbei wird für das Monitoring unterschieden, ob die Daten vom \ac{TLS} oder vom \ac{RM} von Hadoop abgerufen werden.
Dies ist vor allem bei der Nutzung der REST"=API wichtig, da sich hier die Adressen und Pfade unterscheiden, während bei der Benutzung der CLI die Befehle gleich sind .
Der \ac{TLS} wird zum Abrufen der Daten vor allem aus dem Grund genutzt, da hierbei zusätzliche Daten ermittelt werden können, die bei der reinen Nutzung der Schnittstellen des \ac{RM} nicht zurückgegeben werden würden.
Ausgenommen sind hiervon Anwendungen, bei denen die Nutzung des \ac{TLS} keine weiteren Daten von Hadoop zurückgegeben werden\cite{HadoopYarnTlServer271,HadoopYarnCmds271,HadoopRmApi271,HadoopNmApi271}.
Aus diesem Grund ist die Nutzung des \ac{TLS} zum Monitoring von Anwendungen mithilfe des Connector"=Interfaces nicht möglich.

Die Implementierten Parser und Connectoren sind jeweils als Singleton realisiert und sind von der Serialisierung des YARN"=Modells durch \ac{ss} ausgenommen.
Dies liegt vor allem darin Begründet, dass dadurch Speicher eingespart wird, der dadurch für andere YARN"=Komponenten zur Verfügung steht.
Aber auch weitere Einschränkungen durch \ac{ss} spielten eine Rolle (vgl. \cref{sec:ssharp}).
Ein weiterer Vorteil liegt zudem darin, dass für Unterschiedliche Einsatzzwecke der gleiche Connector genutzt werden kann, und somit auch die einzelnen vom Connector benötigten SSH"=Verbindungen für unterschiedliche Einsatzzwecke wiederverwendet werden können.
Die Initialisierung der Parser und Connectoren erfolgt jeweils beim ersten Aufruf der Singletons.
Dies geschieht innerhalb des Testsystems üblicherweise entweder beim Initialisieren des Tests (beschrieben in \cref{sec:implTestcases}) oder beim Initialisieren des YARN"=Modells selbst durch die Klasse \texttt{Model}.
Die Initialisierung des Modells stellt zudem den einzigen Zeitpunkt dar, bei dem im YARN"=Modell direkt mit den implementierten Parsern und Connectoren interagiert wird, jede andere Interaktion findet stattdessen gekapselt mithilfe der Interfaces statt.

Die drei Komponenten des Treibers sind zudem untereinander  voneinander gekapselt.
Bei der Ausführung des Parsers wird daher analog nur zur Initialisierung mit dem konkreten Connector interagiert, während das Connector"=Interface zum Monitoring als einzige Schnittstelle dient.
Da für die SSH"=Verbindung kein eigenes Interface zur Kapselung existiert, ist die Kapselung der Connectoren und der bereitstellenden Klasse der SSH"=Verbindung nicht so streng wie zwischen anderen Komponenten.
Dennoch werden Befehle auf den Cluster"=Hosts ausschließlich mithilfe des Connectors durchgeführt.

\subsection{Entwicklung der Parser}
\label{subsec:implementedParsers}

Der Parser dient dazu, die von Hadoop zurückgegebenen Daten der YARN"=Komponenten einzulesen und dem Modell zu übergeben.
Zur Datenhaltung innerhalb der Parser"=Komponente des Treibers wurden hierfür entsprechende Klassen entwickelt, welche die von \texttt{IParsedComponent} abgeleiteten Interfaces implementieren.
Dadurch sind die Datenhaltungs"=Klassen auch direkt dafür geeignet, die Daten an das Modell zu übergeben.

Wenn Daten durch den Parser abgefragt und konvertiert werden sollen, ist der grundlegende Ablauf immer der gleiche.
Zunächst werden, sofern benötigt, die IDs von weiteren benötigten YARN"=Komponenten ermittelt, bevor die Rohdaten durch einen passenden Connector ermittelt werden.
Die Rohdaten werden anschließend konvertiert und in der entsprechenden Datenhaltungs"=Klasse gespeichert, welche mithilfe der entsprechenden von \texttt{IParsedComponent} abgeleiteten Interfaces zurückgegeben.

Da Hadoop zwei Schnittstellen in Form der CLI und der REST"=API bereit stellt, wurden hierfür entsprechend zwei Parser entwickelt, um die jeweiligen Daten einzulesen.

\subsubsection{Implementierung des CmdParsers}
\label{subsubsec:implCmdParser}

Der erste der beiden entwickelten Parser ist der \texttt{CmdParser} zum Monitoring mithilfe von Befehlen auf der CLI.
Zum Auslesen der Daten selbst nutzt der \texttt{CmdParser} den dazugehörigen \texttt{CmdConnector} (vgl. \cref{subsubsec:implCmdConnector}), mit dem zum Auslesen der Daten die entsprechenden CLI"=Befehle ausgeführt werden.
Die hierbei zurückgegebenen Daten sind im Vergleich zu den von der REST"=API zurückgegebenen im Umfang deutlich reduziert, in den jeweiligen Übersichten der Subkomponenten zudem auf das notwendigste beschränkt.
Im Gegenzug zur REST"=API werden hier die Daten des \ac{RM} und \ac{TLS} kombiniert ausgegeben.
Eine kurze Übersicht über die Befehle und deren Ausgaben ist im \cref{app:hadoopCmds} zu finden.

Ausgewertet werden die von Hadoop zurückgegebenen Daten mithilfe von \acp{Regex}.
Da das Ausgabeformat jeweils in Listenform oder als ausführlicher Report immer das gleiche Format aufweist, wurden hierfür zwei generische Regex"=Pattern entwickelt, welche zur Auswertung fast aller Daten ausreichend sind:

\begin{lstlisting}[label=lst:cmdRegexPattern,style=cs,
caption={[Implementierte \acs{Regex}"=Pattern im CmdParser]
    Implementierte \acs{Regex}"=Pattern im \texttt{CmdParser}}]
Regex _GenericListRegex = new Regex(@"\s*([^\t]+)");
Regex _GenericDetailsRegex = new Regex(@"\t(.+)\s:\s([^\t]*)[\n\r]", RegexOptions.Multiline);
\end{lstlisting}

Bei zurückgegebenen Listen müssen diese zur Auswertung zunächst zeilenweise getrennt werden, bevor das Regex"=Pattern genutzt werden kann.
Anschließend können durch die Reihenfolge der jeweiligen Regex"=Matchgruppen die jeweiligen Daten der Komponente den entsprechenden Eigenschaften der Datenhaltungsklassen zugeordnet werden.

Eine Besonderheit bilden Zeitstempel.
Diese werden von Hadoop bei der Nutzung der CLI meist in Form des Java"=Timestamps in Millisekunden seit dem 1. Januar 1970 00:00:00 Uhr, in der Liste der ausgeführten Container eines Attempts stattdessen im Format \texttt{ddd MMM dd HH:mm:ss zz00 yyyy}.
Dies entspricht \zB dem Zeitstempel \texttt{Fri Jan 05 11:08:16 +0000 2018}.
Weiterführende Informationen zur Formatierung von Zeitstempeln in .NET finden sich in \cite{CsTimeFormatStrings}.
Der von Hadoop zurückgegebene Zeitstempel muss in beiden Fällen zunächst in ein .NET"=kompatibles Format umgewandelt werden.
Dies geschieht mithilfe der Methode \texttt{ParseJavaTimestamp()}, für die mehrere Überladungen implementiert wurden:

\begin{lstlisting}[label=lst:parseJavaTimestamp,style=cs,
caption={[Überladungen der Methode ParseJavaTimestamp()]
    Überladungen der Methode \texttt{ParseJavaTimestamp()}.
    Es steht zudem eine weitere Überladung zur Verfügung, um den Timestamp in Form der Millisekunden seit 1970 als \texttt{string} zu übergeben.
    Dabei wird der \texttt{string} in einen \texttt{long} konvertiert und anschließend die erste hier gezeigte Überladung aufgerufen.}]
public static DateTime ParseJavaTimestamp(long javaMillis)
{
  if(javaMillis < 1)
  return DateTime.MinValue;
  var javaTimeUtc = new DateTime(1970, 1, 1, 0, 0, 0,
     DateTimeKind.Utc).AddMilliseconds(javaMillis);
  return javaTimeUtc.ToLocalTime();
}

public static DateTime ParseJavaTimestamp(string value,
   string format, CultureInfo culture = null)
{
  culture = culture ?? new CultureInfo("en-US");
  DateTime time;
  DateTime.TryParseExact(value, format, culture,
     DateTimeStyles.AssumeUniversal, out time);
  return time;
}
\end{lstlisting}

Die hierbei zurückgegebenen \texttt{DateTime}"=Instanzen werden anschließend zum Speichern der Zeitstempel genutzt.

Die Speicherung und Übergabe der ausführenden Nodes des \ac{AppMstr} oder der Container an das Modell geschieht direkt als entsprechende Node"=Instanz innerhalb des Modells.
Hierfür wird die ID bzw. die URL des Nodes genutzt, um die korrespondierende Instanz im \ac{YARN}"=Modell zu ermitteln und zu speichern.

\subsubsection{Implementierung des RestParsers}
\label{subsubsec:implRestParser}

Der zweite entwickelte Parser ist der \texttt{RestParser}.
Er dient dazu, die mithilfe der REST"=API ermittelten Daten auszuwerten und an das YARN"=Modell zu übergeben.
Zum Auslesen der Daten aus dem Cluster wurde hierfür der \texttt{RestConnector} entwickelt (vgl. \cref{subsubsec:implRestConnector}).
Die REST"=API besitzt, auch im Vergleich zur CLI"=Schnittstelle, einige Besonderheiten, auf die bei der Implementierung geachtet werden musste \cite{HadoopYarnCmds271,HadoopRmApi271,HadoopNmApi271,HadoopYarnTlServer271}:

\begin{itemize}
    \item Die zurückgegebenen Daten sind deutlich Umfangreicher als bei der CLI"=Schnittstelle
    \item Die Daten können im XML- oder JSON"=Format zurückgegebenen werden
    \item Attempts können nur als Liste aller Attempts einer Anwendung zurückgegeben werden
    \item Daten zu Containern können nur durch die \ac{NM} der ausführenden Nodes ermittelt werden
    \item Die Adressen und Pfade von \ac{RM}, \ac{NM} und \ac{TLS} unterscheiden sich
    \item Die Daten von \ac{RM} und \ac{NM} sind immer umfangreicher als die des \ac{TLS}
    \item Der \ac{TLS} enthält für Attempts und Anwendungs"=Container jedoch zusätzliche Daten
    \item Es werden bei Listen und Reports immer die gleichen Objekte der YARN"=Komponenten zurückgegebenen
\end{itemize}

Da die REST"=API die Rückgabe der Daten in zwei Formaten ermöglicht, wurde der \texttt{RestParser} aufgrund der kleineren Datenmengen und übersichtlicheren Datenformats zur Nutzung des JSON"=Formats entwickelt
Einige Beispiele für die entsprechenden Pfade der REST"=API sowie deren Ausgaben im JSON"=Format sind in \cref{app:hadoopRestApi} zu finden.

Die Auswertung der Daten geschieht beim \texttt{RestParser} zudem nicht mit Regex, sondern mithilfe des \emph{Json.NET}"=Frameworks\footnote{\url{https://www.newtonsoft.com/json}}.
Hierfür wurden neben den bestehenden Datenhaltungsklassen noch weitere Hilfsklassen entwickelt, welche das Ausgabeformat der REST"=API nachbilden.
Mit deren Hilfe ist es möglich, alle Daten automatisch mithilfe von Json.NET aus den JSON"=Daten deserialisieren zu können.

Analog zum \texttt{CmdParser} müssen auch bei der Nutzung der REST"=API die Zeitstempel gesondert betrachtet werden.
Damit die Konvertierung der Java"=Zeitstempel in Millisekunden seit dem 1. Januar 1970 00:00:00 Uhr gemeinsam mit den anderen Daten durch das Json.NET"=Framework durchgeführt werden kann, musste hierfür ein gesonderter Konverter entwickelt werden.
Der Konverter nutzt ebenfalls die in \cref{lst:parseJavaTimestamp} gezeigte \texttt{ParseJavaTimestamp()} zum Konvertieren der Daten:

\begin{lstlisting}[label=lst:javaEpochConverter,style=cs,
caption={[Entwickelter Konverter für Java"=Zeitstempel zur Nutzung mit Json.NET]
    Entwickelter Konverter für Java"=Zeitstempel zur Nutzung mit Json.NET.
    Dieser erbt dafür von \texttt{DateTimeConverterBase} des Json.NET"=Frameworks, damit der \texttt{JsonJavaEpochConverter} auch zur Deserialisierung genutzt werden kann.}]
public class JsonJavaEpochConverter : DateTimeConverterBase
{
  private static readonly DateTime _Epoch = new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc);

  public override void WriteJson(JsonWriter writer, object value, JsonSerializer serializer)
  {
    writer.WriteRawValue(((DateTime)value - _Epoch).TotalMilliseconds.ToString());
  }
  
  public override object ReadJson(JsonReader reader, Type objectType, object existingValue, JsonSerializer serializer)
  {
    return DriverUtilities.ParseJavaTimestamp((long)reader.Value);
  }
}
\end{lstlisting}

Da der \ac{TLS} bei der Ausgabe der Daten zu Attempts und Containern zusätzliche Informationen enthält, werden hier nicht nur die Daten mithilfe des \ac{RM} bzw. der \ac{NM} der ausführenden Nodes, sondern auch mithilfe des \ac{TLS}.
Hierzu werden zunächst die Daten des \ac{RM} bzw. der \ac{NM} ermittelt und mit die zusätzlichen Informationen des \ac{TLS} ergänzt, sofern hier Daten verfügbar sind.
Aufgrund der Besonderheiten der REST"=API im Bezug auf Attempts und Container, werden bei diesen beiden YARN"=Komponenten zunächst immer die Daten aller Attempts einer Anwendung bzw. aller Container eines Attempts ermittelt und konvertiert.
Sollten jedoch nur die Daten jeweils eines Attempts bzw. Containers benötigt werden, werden diese Listen entsprechend gefiltert:

\begin{lstlisting}[label=lst:restParseDetails,style=cs,
caption={[Konvertierung und Rückgabe der Daten eines einzelnen Containers durch den RestParser]
    Konvertierung und Rückgabe der Daten eines einzelnen Containers durch den \texttt{RestParser}.
    Hierbei muss zunächst die ID des übergeordneten Attempts ermittelt werden, bevor aus der Liste aller Container die Daten des gesuchten Containers zurückgegeben werden können.
    Bei Attempts ist dieses Vorgehen analog.}]
public IContainerResult ParseContainerDetails(string containerId)
{
  var attemptId = DriverUtilities.ConvertId(containerId, EConvertType.Attempt);
  var allContainers = ParseContainerList(attemptId);
  return allContainers.FirstOrDefault(c => c.ContainerId == containerId);
}
\end{lstlisting}

Aufgrund dieser Besonderheiten eignet sich auch das in \cref{subsubsec:yarnComponentInterface} beschriebene Monitoring durch die übergeordnete Komponente bei der Nutzung der REST"=API besser als das Selbstmonitoring.

\subsection{Entwicklung der Connectoren}
\label{subsec:implementedConnectors}



\subsubsection{Implementierung des CmdConnectors}
\label{subsubsec:implCmdConnector}

\subsubsection{Implementierung des RestConnectors}
\label{subsubsec:implRestConnector}

\subsection{Implementierung der SSH"=Verbindung}
\label{subsec:sshConnection}



%\subsection{Implementierte Connectoren}
%\label{subsec:implementedConnectors}
%
%Für die beiden Parser wurden die beiden korrespondieren Connectoren \texttt{CmdConnector} und \texttt{RestConnector} entwickelt.
%Während der Connector für die REST"=API nur über eine SSH"=Verbindung verfügt, besteht beim Connector für die Kommandozeile die Möglichkeit, mehrere einzelne SSH"=Verbindungen zu nutzen.
%Dies ist damit begründet, dass zum Steuern der Komponentenfehler, was nur über die Kommandozeile möglich ist, eine eigene SSH"=Verbindung genutzt wird.
%Zum Starten von Anwendungen besteht zudem die Möglichkeit, eine beliebige Anzahl an einzelnen SSH"=Verbindungen aufzubauen, damit mehrere Anwendungen parallel gestartet werden können.
%Da die Daten der einzelnen YARN"=Komponenten in der Fallstudie bevorzugt mithilfe der REST"=API ermittelt werden, kann die dafür vorgesehene SSH"=Verbindung des \texttt{CmdConnector} deaktiviert werden.
%
%Da über die Kommandozeile die Befehle für die Daten vom \ac{TLS} die gleichen wie für die Daten vom \ac{RM} sind \cite{HadoopYarnTlServer271,HadoopYarnCmds271}, sind beim \texttt{CmdConnector} die \ac{TLS}"=Methoden von geringer Bedeutung und nutzen daher ebenfalls die \ac{RM}"=Methoden.
%
%Der Connector ist beim Abrufen der Daten dafür zuständig, die dafür notwendigen Befehle auszuführen.
%Während dies für die Kommandozeilen"=Befehle die entsprechenden Hadoop"=Befehle sind, wird dies zum Abrufen der Daten über die REST"=API mithilfe des Tools \emph{curl} durchgeführt.
%Die dabei zurückgegebenen Daten werden vom Connector ohne Verarbeitung zurückgegeben und können dann vom Parser verarbeitet werden.
%
%Beim Steuern der Komponentenfehler wird vom Connector das für die Fallstudie entwickelte Start"=Script verwendet.
%Nach dem eigentlichen Start bzw. Aufheben eines Komponentenfehlers wird vom Connector zudem überprüft, ob die Injizierung bzw. Aufhebung erfolgreich war.
%Während der Datenabruf sowie die Steuerung der Komponentenfehler synchron stattfindet, findet das Starten der Anwendungen asynchron und mithilfe des Benchmark"=Scriptes statt.
%Da eine Ausführung einer YARN"=Anwendung längere Zeit in Anspruch nehmen kann, wird dadurch die Ausführung von \sS nicht behindert und es können mehrere Anwendungen parallel ausgeführt werden.
%
%\subsection{SSH"=Verbindung}
%\label{subsec:sshConnection}
%
%Die SSH"=Verbindung selbst ist der einzige Bestandteil des Treibers, welches kein entsprechendes Interface benötigt, die SSH"=Verbindung wird ausschließlich vom Connector genutzt.
%Realisiert wird die Verbindung mithilfe des Frameworks SSH.NET,\footnote{\url{https://github.com/sshnet/SSH.NET}} weshalb die SSH"=Verbindung im Treiber nur entsprechende Funktionen zum Aufbauen, Nutzen und Beenden der Verbindung enthält.
%
%Um die Verbindung mit dem Cluster"=PC aufzubauen, ist zudem ein dort installierter SSH"=Key nötig.
%Ein Kommando auf dem Cluster"=PC kann mithilfe der Treiberkomponente synchron und asynchron ausgeführt werden.
