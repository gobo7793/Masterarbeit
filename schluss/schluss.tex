\chapter{Reflexion und Abschluss}
\label{ch:outro}

Die Evaluation der ausgeführten Tests hat gezeigt, dass sich das entwickelte Testsystem und das Hadoop"=Cluster im Großen und Ganzen so verhalten haben, wie es erwartet wurde (vgl. \cref{sec:evaluationResults}).
Dennoch wurden auffällig viele Anwendungen aufgrund verschiedener Fehler beendet (vgl. \cref{sec:appEval}), was auf Probleme im Testsystem oder der Auswahl der Testkonfiguration hinweist.

Die Analyse der fehlgeschlagenen Anwendungen hat gezeigt, dass es hierfür vier konkrete Ursachen gibt (vgl. \cref{subsec:failedApps}):

\begin{itemize}
    \item Der Node ist nicht erreichbar, was zu einem \gls{AppMstr}"=Timeout führt
    \item Der den \gls{AppMstr} ausführende Node ist zur sehr ausgelastet, was ebenfalls zu einem \gls{AppMstr}"=Timeout führt
    \item Benötigte Dateien im \gls{HDFS} werden nicht gefunden, was in einem Map"=Task"=Fehler resultiert
    \item Es wird versucht, den \gls{AppMstr} auf einem defekten Node auszuführen, was sich im Exitcode -100 zeigt
\end{itemize}

Es ist erkennbar, dass drei der vier Ursachen im direkten oder indirekten Zusammenhang mit der Injizierung von Komponentenfehlern im realen Cluster zusammen hängen.
Dies zeigt sich vor allem an der häufigen Zahl an \gls{AppMstr}"=Timeouts, welche bei einem injiziertem Komponentenfehler die direkte Folge davon ist, wenn auf dem Node ein \gls{AppMstr} ausgeführt wurde.
Es ist daher anzunehmen, dass die in \cref{sec:selectTestcases} ausgewählte generelle Wahrscheinlichkeit zur Aktivierung und Deaktivierung der Komponentenfehler von 0,3 vor allem für hohe Auslastungsgrade eine nicht sehr ausgewogene Mischung ergibt.
Während bei niedrigen Auslastungsgraden kaum Komponentenfehler aktiviert wurden, war die bei hohen Auslastungsgraden häufig der Fall, was sich auch in der Anzahl der 14 abgebrochenen Tests zeigt (vgl. \cref{sec:noReconfig}).

Mit 14 Prozent aller möglichen Komponentenfehler wurden zwar nicht viele Fehler aktiviert.
Jedoch muss man bei diesem Wert beachten, dass für jeden Node pro Testfall bis zu zwei Komponentenfehler aktivierbar sind.
Aus diesem Grund wurden nicht 14 Prozent der möglichen Defekte ausgelöst, sondern rund ein Viertel.
Das ergibt umgerechnet pro ausgeführtem Testfall im Schnitt mindestens einen Node, bei dem ein Komponentenfehler injiziert und somit ein Defekt ausgelöst wurde.
Die Quote von rund einem Viertel defekter Nodes dürfte im Praxisbetrieb jedoch eher unwahrscheinlich sein.
Da viele in der Praxis eingesetzten Cluster eine zwei-, drei- oder zum Teil auch eine vierstellige Zahl an Nodes aufweisen \cite{PoweredByHadoop}, müssten hier für eine ähnliche Quote bis zu mehrere hundert Nodes gleichzeitig ausfallen.
Ein Beispiel mit den Daten des Musik"=Streaming"=Dienstes Spotify\footnote{\url{https://www.spotify.com/}} verdeutlicht hierbei die Tragweite eines solchen Ausfalls.
Das von Spotify genutzte Cluster zur Analyse der Hörgewohnheiten und für Musikempfehlungen für seine Benutzer und Kunden weist folgende Kenndaten auf \cite{PoweredByHadoop}:

\begin{itemize}
    \item 1.650 Nodes
    \item 43.000 virtualisierte Kerne
    \item 70 TB Arbeitsspeicher
    \item 65 PB Speicherplatz
    \item mehr als 20.000 täglich auf dem Cluster ausgeführte Jobs
\end{itemize}

Es stellt damit auch eines der größten Hadoop"=Cluster dar.
Es ist schnell ersichtlich, dass beim Ausfall von über 400 Nodes wohl ein Großteil der über 20.000 ausgeführten Anwendungen nicht mehr ausgeführt werden könnten und einzelne Blöcke von möglicherweise benötigten Daten im \gls{HDFS} nicht mehr verfügbar wären (vgl. \cref{sec:hadoop}).

Daher lässt sich die hohe Anzahl an fehlgeschlagenen Anwendungen wohl vor allem an der generellen Wahrscheinlichkeit zur Aktivierung der Komponentenfehlern festmachen.
Es wäre daher durchaus sinnvoll gewesen, einige der ausgeführten Tests auch ohne Aktivierung der Komponentenfehler durchzuführen.
So hätte besser festgestellt werden können, ob das an zu vielen aktivierten Komponentenfehlern liegt oder ob der Grund im Testsystem selbst liegt.

Jedoch hätten selbst dadurch \uU nicht alle fehlerhaften Anwendungen unterbunden werden können.
Unabhängig von der Anzahl der Nodes gab es zahlreiche Testfälle, bei denen das Cluster vollständig ausgelastet war und daher keine weiteren \gls{AppMstr} ausgeführt werden konnten.
In solchen Fällen kam es oftmals vor, dass einzelne \gls{AppMstr} mit einem Timeout beendet wurden, da die benötigten Ressourcen nicht allokiert werden konnten.
Da es mit \acrlong{dfw}, \acrlong{dfr} und \acrlong{pt} einige Benchmarks gab, welche bereits bei den ausgefühten Tests unabhängig von der Anzahl der aktiven Nodes das komplette Cluster ausgelastet hatten, hätte es hier sehr wahrscheinlich dennoch entsprechende Timeouts gegeben.
Jedoch hätten sich die \gls{AppMstr}"=Timeouts darauf beschränkt, dass keine Ressourcen allokiert werden konnten, was eine deutlich geringere Zahl gewesen wäre.

Durch eine Testausführung ohne Aktivierung der Komponentenfehler hätten vermutlich auch viele der 29 nicht gestarteten Anwendungen (vgl. \cref{subsec:notStartedApps}) gestartet werden können.
Mit 7 Prozent ist der Anteil der nicht gestarteten Anwendungen im Verhältnis zu allen gestarteten Anwendungen zwar kein signifikanter Anteil, aber auch keinen komplett zu vernachlässigender Anteil.
Zwar hätten die nicht gestarteten Anwendungen keine signifikant höhere Auslastung des Clusters bedeutet, aber dennoch wurde hiermit auch eine in \cref{sec:requirements} nicht erwähnte Anforderung verletzt, wonach alle Anwendungen der ausgewählten Benchmarks auch gestartet werden müssten.
Da hierbei immer Anwendungen der Terasort"=Suite betroffen waren, gab es hierfür auch zwei Gründe.
Der erste Grund war eine zu hohe Auslastung des Clusters, wodurch die benötigten Daten von der \acrlong{tg} nicht generiert werden konnten, da die Anwendung keine Ressourcen zur Ausführung des \gls{AppMstr} erhalten hat oder die Anwendung auch deshalb vorab abgebrochen wurde.
Der zweite Grund liegt in der Injizierung der Komponentenfehler, wodurch erfolgreich generierte Daten für die nachfolgenden Anwendungen nicht mehr verfügbar waren.
Es ist daher stark davon auszugehen, dass sich die Anzahl der nicht gestarteten Anwendungen bei einer Testausführung ohne Aktivierungen von Komponentenfehlern signifikant reduzieren würde.

Ein spezieller Fall bildet das Fehlen der Diagnostik"=Daten von ausgeführten Anwendungen.
Hierfür hat sich nach einer Analyse herausgestellt, dass nicht fehlerhafte Daten des Clusters ursächlich waren, sondern ein falsch gesetztes Attribut im Parser (vgl. \cref{subsec:notSavedAppDiagnostics}).
Dies hätte bereits bei Vorabtests wie den durchgeführten Komponententests der beiden implementierten Parser bereits festgestellt und entsprechend korrigiert werden müssen.
